{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTO LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bianc\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bianc\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (2.1.0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bianc\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bianc\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bianc\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bianc\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bianc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bianc\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bianc\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Importar Librerias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Carga de archivos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CommonPlayer=pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\common_player_info.csv')\n",
    "BorradorDeEstadsticasCombinadas=pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\draft_combine_stats.csv')\n",
    "BorradorDeHistoria=pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\draft_history.csv')\n",
    "InformacionDelJuego=pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\game_info.csv')\n",
    "ResumendelJuego=pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\game_summary.csv')\n",
    "Juego=pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\game.csv')\n",
    "JugadoresInactivos=pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\inactive_players.csv')\n",
    "PuntuacionDeLinea=pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\line_score.csv')\n",
    "Oficiales=pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\officials.csv')\n",
    "OtrasEstadisticas=pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\other_stats.csv')\n",
    "JuegoPorJuego=pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\play_by_play.csv')\n",
    "Jugador=pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\player.csv')\n",
    "DetallesDelEquipo=pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\team_details.csv')\n",
    "HistoriaDelEquipo=pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\team_history.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Verificación de cantidad de registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4171, 33)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CommonPlayer.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7990, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BorradorDeHistoria.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58053, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InformacionDelJuego.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58110, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResumendelJuego.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65698, 55)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Juego.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110191, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JugadoresInactivos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58053, 43)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PuntuacionDeLinea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70971, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Oficiales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28271, 26)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OtrasEstadisticas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13592899, 34)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JuegoPorJuego.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4831, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jugador.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DetallesDelEquipo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HistoriaDelEquipo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Verificación de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_id                             0\n",
       "first_name                            0\n",
       "last_name                             0\n",
       "display_first_last                    0\n",
       "display_last_comma_first              0\n",
       "display_fi_last                       0\n",
       "player_slug                           0\n",
       "birthdate                             0\n",
       "school                                0\n",
       "country                               0\n",
       "last_affiliation                      0\n",
       "height                                0\n",
       "weight                                0\n",
       "season_exp                            0\n",
       "jersey                                0\n",
       "position                              0\n",
       "rosterstatus                          0\n",
       "games_played_current_season_flag      0\n",
       "team_id                               0\n",
       "team_name                             0\n",
       "team_abbreviation                     0\n",
       "team_code                           702\n",
       "team_city                             0\n",
       "playercode                            1\n",
       "from_year                             0\n",
       "to_year                               0\n",
       "dleague_flag                          0\n",
       "nba_flag                              0\n",
       "games_played_flag                     0\n",
       "draft_year                            0\n",
       "draft_round                           0\n",
       "draft_number                          0\n",
       "greatest_75_flag                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CommonPlayer.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season                             0\n",
       "player_id                          0\n",
       "first_name                         0\n",
       "last_name                          0\n",
       "player_name                        0\n",
       "position                           5\n",
       "height_wo_shoes                   49\n",
       "height_wo_shoes_ft_in             49\n",
       "height_w_shoes                   194\n",
       "height_w_shoes_ft_in             194\n",
       "weight                            50\n",
       "wingspan                          49\n",
       "wingspan_ft_in                    49\n",
       "standing_reach                    50\n",
       "standing_reach_ft_in              50\n",
       "body_fat_pct                     199\n",
       "hand_length                      483\n",
       "hand_width                       483\n",
       "standing_vertical_leap           185\n",
       "max_vertical_leap                185\n",
       "lane_agility_time                194\n",
       "modified_lane_agility_time       791\n",
       "three_quarter_sprint             190\n",
       "bench_press                      394\n",
       "spot_fifteen_corner_left        1128\n",
       "spot_fifteen_break_left         1126\n",
       "spot_fifteen_top_key            1126\n",
       "spot_fifteen_break_right        1126\n",
       "spot_fifteen_corner_right       1126\n",
       "spot_college_corner_left         957\n",
       "spot_college_break_left         1036\n",
       "spot_college_top_key            1036\n",
       "spot_college_break_right        1036\n",
       "spot_college_corner_right       1036\n",
       "spot_nba_corner_left             985\n",
       "spot_nba_break_left              985\n",
       "spot_nba_top_key                 985\n",
       "spot_nba_break_right             985\n",
       "spot_nba_corner_right            985\n",
       "off_drib_fifteen_break_left     1036\n",
       "off_drib_fifteen_top_key        1036\n",
       "off_drib_fifteen_break_right    1036\n",
       "off_drib_college_break_left     1092\n",
       "off_drib_college_top_key        1171\n",
       "off_drib_college_break_right    1171\n",
       "on_move_fifteen                 1054\n",
       "on_move_college                 1086\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BorradorDeEstadsticasCombinadas.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_id               0\n",
       "player_name             0\n",
       "season                  0\n",
       "round_number            0\n",
       "round_pick              0\n",
       "overall_pick            0\n",
       "draft_type              0\n",
       "team_id                 0\n",
       "team_city               0\n",
       "team_name               0\n",
       "team_abbreviation       0\n",
       "organization           19\n",
       "organization_type      19\n",
       "player_profile_flag     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BorradorDeHistoria.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game_id           0\n",
       "game_date         0\n",
       "attendance     5380\n",
       "game_time     28111\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InformacionDelJuego.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game_date_est                           0\n",
       "game_sequence                       25532\n",
       "game_id                                 0\n",
       "game_status_id                          0\n",
       "game_status_text                    25986\n",
       "gamecode                                0\n",
       "home_team_id                            0\n",
       "visitor_team_id                         0\n",
       "season                                  0\n",
       "live_period                             0\n",
       "live_pc_time                        56086\n",
       "natl_tv_broadcaster_abbreviation    51907\n",
       "live_period_time_bcast                  0\n",
       "wh_status                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResumendelJuego.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season_id                     0\n",
       "team_id_home                  0\n",
       "team_abbreviation_home        0\n",
       "team_name_home                0\n",
       "game_id                       0\n",
       "game_date                     0\n",
       "matchup_home                  0\n",
       "wl_home                       2\n",
       "min                           0\n",
       "fgm_home                     13\n",
       "fga_home                  15447\n",
       "fg_pct_home               15490\n",
       "fg3m_home                 13218\n",
       "fg3a_home                 18683\n",
       "fg3_pct_home              19074\n",
       "ftm_home                     16\n",
       "fta_home                   3004\n",
       "ft_pct_home                3009\n",
       "oreb_home                 18936\n",
       "dreb_home                 18999\n",
       "reb_home                  15729\n",
       "ast_home                  15805\n",
       "stl_home                  18849\n",
       "blk_home                  18626\n",
       "tov_home                  18684\n",
       "pf_home                    2856\n",
       "pts_home                      0\n",
       "plus_minus_home               0\n",
       "video_available_home          0\n",
       "team_id_away                  0\n",
       "team_abbreviation_away        0\n",
       "team_name_away                0\n",
       "matchup_away                  0\n",
       "wl_away                       2\n",
       "fgm_away                     13\n",
       "fga_away                  15447\n",
       "fg_pct_away               15489\n",
       "fg3m_away                 13218\n",
       "fg3a_away                 18683\n",
       "fg3_pct_away              18962\n",
       "ftm_away                     13\n",
       "fta_away                   3004\n",
       "ft_pct_away                3006\n",
       "oreb_away                 18936\n",
       "dreb_away                 18998\n",
       "reb_away                  15725\n",
       "ast_away                  15801\n",
       "stl_away                  18849\n",
       "blk_away                  18625\n",
       "tov_away                  18685\n",
       "pf_away                    2851\n",
       "pts_away                      0\n",
       "plus_minus_away               0\n",
       "video_available_away          0\n",
       "season_type                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Juego.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game_id               0\n",
       "player_id             0\n",
       "first_name            1\n",
       "last_name             1\n",
       "jersey_num           43\n",
       "team_id               0\n",
       "team_city             0\n",
       "team_name             0\n",
       "team_abbreviation     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JugadoresInactivos.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game_date_est                 0\n",
       "game_sequence             25532\n",
       "game_id                       0\n",
       "team_id_home                  0\n",
       "team_abbreviation_home        0\n",
       "team_city_name_home           0\n",
       "team_nickname_home            0\n",
       "team_wins_losses_home         0\n",
       "pts_qtr1_home              1004\n",
       "pts_qtr2_home              1013\n",
       "pts_qtr3_home              1045\n",
       "pts_qtr4_home              1044\n",
       "pts_ot1_home              25759\n",
       "pts_ot2_home              27051\n",
       "pts_ot3_home              27243\n",
       "pts_ot4_home              27270\n",
       "pts_ot5_home              45577\n",
       "pts_ot6_home              45578\n",
       "pts_ot7_home              45578\n",
       "pts_ot8_home              45578\n",
       "pts_ot9_home              45578\n",
       "pts_ot10_home             45578\n",
       "pts_home                      0\n",
       "team_id_away                  0\n",
       "team_abbreviation_away        0\n",
       "team_city_name_away           0\n",
       "team_nickname_away            0\n",
       "team_wins_losses_away         0\n",
       "pts_qtr1_away              1010\n",
       "pts_qtr2_away              1013\n",
       "pts_qtr3_away              1046\n",
       "pts_qtr4_away              1046\n",
       "pts_ot1_away              25759\n",
       "pts_ot2_away              27051\n",
       "pts_ot3_away              27243\n",
       "pts_ot4_away              27270\n",
       "pts_ot5_away              45577\n",
       "pts_ot6_away              45578\n",
       "pts_ot7_away              45578\n",
       "pts_ot8_away              45578\n",
       "pts_ot9_away              45578\n",
       "pts_ot10_away             45578\n",
       "pts_away                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PuntuacionDeLinea.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game_id          0\n",
       "official_id      0\n",
       "first_name       0\n",
       "last_name        0\n",
       "jersey_num     190\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Oficiales.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game_id                      0\n",
       "league_id                    0\n",
       "team_id_home                 0\n",
       "team_abbreviation_home       0\n",
       "team_city_home               0\n",
       "pts_paint_home               0\n",
       "pts_2nd_chance_home          0\n",
       "pts_fb_home                  0\n",
       "largest_lead_home            0\n",
       "lead_changes                 0\n",
       "times_tied                   0\n",
       "team_turnovers_home          2\n",
       "total_turnovers_home       316\n",
       "team_rebounds_home        1998\n",
       "pts_off_to_home           2123\n",
       "team_id_away                 0\n",
       "team_abbreviation_away       0\n",
       "team_city_away               0\n",
       "pts_paint_away               0\n",
       "pts_2nd_chance_away          0\n",
       "pts_fb_away                  0\n",
       "largest_lead_away            0\n",
       "team_turnovers_away          2\n",
       "total_turnovers_away       316\n",
       "team_rebounds_away        1998\n",
       "pts_off_to_away           2123\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OtrasEstadisticas.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game_id                             0\n",
       "eventnum                            0\n",
       "eventmsgtype                        0\n",
       "eventmsgactiontype                  0\n",
       "period                              0\n",
       "wctimestring                      950\n",
       "pctimestring                        0\n",
       "homedescription               6530241\n",
       "neutraldescription           13273327\n",
       "visitordescription            6634527\n",
       "score                        10028436\n",
       "scoremargin                  10028436\n",
       "person1type                      3298\n",
       "player1_id                          0\n",
       "player1_name                  1208875\n",
       "player1_team_id               1215858\n",
       "player1_team_city             1215858\n",
       "player1_team_nickname         1215858\n",
       "player1_team_abbreviation     1215858\n",
       "person2type                         0\n",
       "player2_id                          0\n",
       "player2_name                  9683745\n",
       "player2_team_id               9660454\n",
       "player2_team_city             9660454\n",
       "player2_team_nickname         9660454\n",
       "player2_team_abbreviation     9660454\n",
       "person3type                         0\n",
       "player3_id                          0\n",
       "player3_name                 13251785\n",
       "player3_team_id              13246931\n",
       "player3_team_city            13246931\n",
       "player3_team_nickname        13246931\n",
       "player3_team_abbreviation    13246931\n",
       "video_available_flag                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JuegoPorJuego.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "full_name     0\n",
       "first_name    6\n",
       "last_name     0\n",
       "is_active     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jugador.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "team_id               0\n",
       "abbreviation          0\n",
       "nickname              0\n",
       "yearfounded           0\n",
       "city                  0\n",
       "arena                 0\n",
       "arenacapacity         9\n",
       "owner                 0\n",
       "generalmanager        0\n",
       "headcoach             1\n",
       "dleagueaffiliation    0\n",
       "facebook              0\n",
       "instagram             0\n",
       "twitter               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DetallesDelEquipo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "team_id             0\n",
       "city                0\n",
       "nickname            0\n",
       "year_founded        0\n",
       "year_active_till    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HistoriaDelEquipo.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratamiento de Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person_id                             0\n",
      "first_name                            0\n",
      "last_name                             0\n",
      "display_first_last                    0\n",
      "display_last_comma_first              0\n",
      "display_fi_last                       0\n",
      "player_slug                           0\n",
      "birthdate                             0\n",
      "school                                0\n",
      "country                               0\n",
      "last_affiliation                      0\n",
      "height                                0\n",
      "weight                                0\n",
      "season_exp                            0\n",
      "jersey                                0\n",
      "position                              0\n",
      "rosterstatus                          0\n",
      "games_played_current_season_flag      0\n",
      "team_id                               0\n",
      "team_name                             0\n",
      "team_abbreviation                     0\n",
      "team_code                           702\n",
      "team_city                             0\n",
      "playercode                            1\n",
      "from_year                             0\n",
      "to_year                               0\n",
      "dleague_flag                          0\n",
      "nba_flag                              0\n",
      "games_played_flag                     0\n",
      "draft_year                            0\n",
      "draft_round                           0\n",
      "draft_number                          0\n",
      "greatest_75_flag                      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_8820\\3512128169.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CommonPlayer['height'].fillna(CommonPlayer['height'].median(), inplace=True)\n",
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_8820\\3512128169.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CommonPlayer['school'].fillna('Desconocido', inplace=True)\n",
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_8820\\3512128169.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CommonPlayer['country'].fillna('Desconocido', inplace=True)\n",
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_8820\\3512128169.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CommonPlayer['position'].fillna('Desconocido', inplace=True)\n",
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_8820\\3512128169.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CommonPlayer['weight'].fillna(CommonPlayer['weight'].median(), inplace=True)\n",
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_8820\\3512128169.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CommonPlayer['jersey'].fillna(0, inplace=True)\n",
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_8820\\3512128169.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CommonPlayer['team_name'].fillna('Sin equipo', inplace=True)\n",
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_8820\\3512128169.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CommonPlayer['team_abbreviation'].fillna('Sin equipo', inplace=True)\n",
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_8820\\3512128169.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CommonPlayer['team_city'].fillna('Sin equipo', inplace=True)\n",
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_8820\\3512128169.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CommonPlayer['draft_round'].fillna(0, inplace=True)\n",
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_8820\\3512128169.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CommonPlayer['draft_number'].fillna(0, inplace=True)\n",
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_8820\\3512128169.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CommonPlayer['from_year'].fillna(0, inplace=True)\n",
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_8820\\3512128169.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CommonPlayer['to_year'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convertir altura en formato 'pies-pulgadas' a pulgadas\n",
    "def convertir_altura_a_pulgadas(altura):\n",
    "    try:\n",
    "        pies, pulgadas = altura.split('-')\n",
    "        return int(pies) * 12 + int(pulgadas)\n",
    "    except:\n",
    "        return np.nan  # Devolver NaN si no se puede convertir\n",
    "\n",
    "# Aplicar la conversión a la columna 'height'\n",
    "CommonPlayer['height'] = CommonPlayer['height'].apply(convertir_altura_a_pulgadas)\n",
    "\n",
    "# Ahora que la columna es numérica, podemos llenar los valores nulos con la mediana\n",
    "CommonPlayer['height'].fillna(CommonPlayer['height'].median(), inplace=True)\n",
    "\n",
    "# Rellenar valores nulos en las demás columnas como antes\n",
    "CommonPlayer['school'].fillna('Desconocido', inplace=True)\n",
    "CommonPlayer['country'].fillna('Desconocido', inplace=True)\n",
    "CommonPlayer['position'].fillna('Desconocido', inplace=True)\n",
    "\n",
    "# Para 'weight', asumimos que es numérica; llenar con la mediana si es así\n",
    "CommonPlayer['weight'] = pd.to_numeric(CommonPlayer['weight'], errors='coerce')\n",
    "CommonPlayer['weight'].fillna(CommonPlayer['weight'].median(), inplace=True)\n",
    "\n",
    "CommonPlayer['jersey'].fillna(0, inplace=True)\n",
    "CommonPlayer['team_name'].fillna('Sin equipo', inplace=True)\n",
    "CommonPlayer['team_abbreviation'].fillna('Sin equipo', inplace=True)\n",
    "CommonPlayer['team_city'].fillna('Sin equipo', inplace=True)\n",
    "\n",
    "CommonPlayer['draft_round'].fillna(0, inplace=True)\n",
    "CommonPlayer['draft_number'].fillna(0, inplace=True)\n",
    "\n",
    "CommonPlayer['from_year'].fillna(0, inplace=True)\n",
    "CommonPlayer['to_year'].fillna(0, inplace=True)\n",
    "\n",
    "# Verificar que no queden valores nulos\n",
    "print(CommonPlayer.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person_id                           0\n",
      "first_name                          0\n",
      "last_name                           0\n",
      "display_first_last                  0\n",
      "display_last_comma_first            0\n",
      "display_fi_last                     0\n",
      "player_slug                         0\n",
      "birthdate                           0\n",
      "school                              0\n",
      "country                             0\n",
      "last_affiliation                    0\n",
      "height                              0\n",
      "weight                              0\n",
      "season_exp                          0\n",
      "jersey                              0\n",
      "position                            0\n",
      "rosterstatus                        0\n",
      "games_played_current_season_flag    0\n",
      "team_id                             0\n",
      "team_name                           0\n",
      "team_abbreviation                   0\n",
      "team_code                           0\n",
      "team_city                           0\n",
      "playercode                          0\n",
      "from_year                           0\n",
      "to_year                             0\n",
      "dleague_flag                        0\n",
      "nba_flag                            0\n",
      "games_played_flag                   0\n",
      "draft_year                          0\n",
      "draft_round                         0\n",
      "draft_number                        0\n",
      "greatest_75_flag                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Rellenar el valor nulo en 'playercode' con 'Desconocido'\n",
    "InformacionComunDelJugador['playercode'].fillna('Desconocido', inplace=True)\n",
    "\n",
    "# Verificar nuevamente que no queden valores nulos\n",
    "print(InformacionComunDelJugador.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season                            0\n",
      "player_id                         0\n",
      "first_name                        0\n",
      "last_name                         0\n",
      "player_name                       0\n",
      "position                          0\n",
      "height_wo_shoes                   0\n",
      "height_wo_shoes_ft_in            49\n",
      "height_w_shoes                    0\n",
      "height_w_shoes_ft_in            194\n",
      "weight                            0\n",
      "wingspan                          0\n",
      "wingspan_ft_in                   49\n",
      "standing_reach                    0\n",
      "standing_reach_ft_in             50\n",
      "body_fat_pct                      0\n",
      "hand_length                       0\n",
      "hand_width                        0\n",
      "standing_vertical_leap            0\n",
      "max_vertical_leap                 0\n",
      "lane_agility_time                 0\n",
      "modified_lane_agility_time      791\n",
      "three_quarter_sprint              0\n",
      "bench_press                     394\n",
      "spot_fifteen_corner_left          0\n",
      "spot_fifteen_break_left           0\n",
      "spot_fifteen_top_key              0\n",
      "spot_fifteen_break_right          0\n",
      "spot_fifteen_corner_right         0\n",
      "spot_college_corner_left          0\n",
      "spot_college_break_left           0\n",
      "spot_college_top_key              0\n",
      "spot_college_break_right          0\n",
      "spot_college_corner_right         0\n",
      "spot_nba_corner_left              0\n",
      "spot_nba_break_left               0\n",
      "spot_nba_top_key                  0\n",
      "spot_nba_break_right              0\n",
      "spot_nba_corner_right             0\n",
      "off_drib_fifteen_break_left       0\n",
      "off_drib_fifteen_top_key          0\n",
      "off_drib_fifteen_break_right      0\n",
      "off_drib_college_break_left       0\n",
      "off_drib_college_top_key          0\n",
      "off_drib_college_break_right      0\n",
      "on_move_fifteen                   0\n",
      "on_move_college                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Llenar valores nulos en columnas específicas\n",
    "\n",
    "# Position\n",
    "BorradorDeEstadsticasCombinadas['position'].fillna('Desconocido', inplace=True)\n",
    "\n",
    "# Alturas y peso\n",
    "BorradorDeEstadsticasCombinadas['height_wo_shoes'].fillna(BorradorDeEstadsticasCombinadas['height_wo_shoes'].median(), inplace=True)\n",
    "BorradorDeEstadsticasCombinadas['height_w_shoes'].fillna(BorradorDeEstadsticasCombinadas['height_w_shoes'].median(), inplace=True)\n",
    "BorradorDeEstadsticasCombinadas['weight'].fillna(BorradorDeEstadsticasCombinadas['weight'].median(), inplace=True)\n",
    "\n",
    "# Medidas de alcance y salto\n",
    "BorradorDeEstadsticasCombinadas['wingspan'].fillna(BorradorDeEstadsticasCombinadas['wingspan'].median(), inplace=True)\n",
    "BorradorDeEstadsticasCombinadas['standing_reach'].fillna(BorradorDeEstadsticasCombinadas['standing_reach'].median(), inplace=True)\n",
    "BorradorDeEstadsticasCombinadas['standing_vertical_leap'].fillna(BorradorDeEstadsticasCombinadas['standing_vertical_leap'].median(), inplace=True)\n",
    "BorradorDeEstadsticasCombinadas['max_vertical_leap'].fillna(BorradorDeEstadsticasCombinadas['max_vertical_leap'].median(), inplace=True)\n",
    "\n",
    "# Porcentaje de grasa corporal\n",
    "BorradorDeEstadsticasCombinadas['body_fat_pct'].fillna(BorradorDeEstadsticasCombinadas['body_fat_pct'].median(), inplace=True)\n",
    "\n",
    "# Longitud y ancho de mano\n",
    "BorradorDeEstadsticasCombinadas['hand_length'].fillna(0, inplace=True)\n",
    "BorradorDeEstadsticasCombinadas['hand_width'].fillna(0, inplace=True)\n",
    "\n",
    "# Pruebas de agilidad y sprint\n",
    "BorradorDeEstadsticasCombinadas['lane_agility_time'].fillna(BorradorDeEstadsticasCombinadas['lane_agility_time'].median(), inplace=True)\n",
    "BorradorDeEstadsticasCombinadas['three_quarter_sprint'].fillna(BorradorDeEstadsticasCombinadas['three_quarter_sprint'].median(), inplace=True)\n",
    "\n",
    "# Estadísticas de tiro\n",
    "cols_tiro = ['spot_fifteen_corner_left', 'spot_fifteen_break_left', 'spot_fifteen_top_key', 'spot_fifteen_break_right', 'spot_fifteen_corner_right', \n",
    "             'spot_college_corner_left', 'spot_college_break_left', 'spot_college_top_key', 'spot_college_break_right', 'spot_college_corner_right',\n",
    "             'spot_nba_corner_left', 'spot_nba_break_left', 'spot_nba_top_key', 'spot_nba_break_right', 'spot_nba_corner_right',\n",
    "             'off_drib_fifteen_break_left', 'off_drib_fifteen_top_key', 'off_drib_fifteen_break_right', 'off_drib_college_break_left', \n",
    "             'off_drib_college_top_key', 'off_drib_college_break_right', 'on_move_fifteen', 'on_move_college']\n",
    "BorradorDeEstadsticasCombinadas[cols_tiro] = BorradorDeEstadsticasCombinadas[cols_tiro].fillna(0)\n",
    "\n",
    "# Verificar valores nulos restantes\n",
    "print(BorradorDeEstadsticasCombinadas.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season                          0\n",
      "player_id                       0\n",
      "first_name                      0\n",
      "last_name                       0\n",
      "player_name                     0\n",
      "position                        0\n",
      "height_wo_shoes                 0\n",
      "height_wo_shoes_ft_in           0\n",
      "height_w_shoes                  0\n",
      "height_w_shoes_ft_in            0\n",
      "weight                          0\n",
      "wingspan                        0\n",
      "wingspan_ft_in                  0\n",
      "standing_reach                  0\n",
      "standing_reach_ft_in            0\n",
      "body_fat_pct                    0\n",
      "hand_length                     0\n",
      "hand_width                      0\n",
      "standing_vertical_leap          0\n",
      "max_vertical_leap               0\n",
      "lane_agility_time               0\n",
      "modified_lane_agility_time      0\n",
      "three_quarter_sprint            0\n",
      "bench_press                     0\n",
      "spot_fifteen_corner_left        0\n",
      "spot_fifteen_break_left         0\n",
      "spot_fifteen_top_key            0\n",
      "spot_fifteen_break_right        0\n",
      "spot_fifteen_corner_right       0\n",
      "spot_college_corner_left        0\n",
      "spot_college_break_left         0\n",
      "spot_college_top_key            0\n",
      "spot_college_break_right        0\n",
      "spot_college_corner_right       0\n",
      "spot_nba_corner_left            0\n",
      "spot_nba_break_left             0\n",
      "spot_nba_top_key                0\n",
      "spot_nba_break_right            0\n",
      "spot_nba_corner_right           0\n",
      "off_drib_fifteen_break_left     0\n",
      "off_drib_fifteen_top_key        0\n",
      "off_drib_fifteen_break_right    0\n",
      "off_drib_college_break_left     0\n",
      "off_drib_college_top_key        0\n",
      "off_drib_college_break_right    0\n",
      "on_move_fifteen                 0\n",
      "on_move_college                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Completar columnas de altura y alcance en pies y pulgadas\n",
    "BorradorDeEstadsticasCombinadas['height_wo_shoes_ft_in'] = BorradorDeEstadsticasCombinadas['height_wo_shoes_ft_in'].fillna(\n",
    "    BorradorDeEstadsticasCombinadas['height_wo_shoes'].apply(lambda x: f\"{int(x // 12)}-{int(x % 12)}\"))\n",
    "BorradorDeEstadsticasCombinadas['height_w_shoes_ft_in'] = BorradorDeEstadsticasCombinadas['height_w_shoes_ft_in'].fillna(\n",
    "    BorradorDeEstadsticasCombinadas['height_w_shoes'].apply(lambda x: f\"{int(x // 12)}-{int(x % 12)}\"))\n",
    "BorradorDeEstadsticasCombinadas['wingspan_ft_in'] = BorradorDeEstadsticasCombinadas['wingspan_ft_in'].fillna(\n",
    "    BorradorDeEstadsticasCombinadas['wingspan'].apply(lambda x: f\"{int(x // 12)}-{int(x % 12)}\"))\n",
    "BorradorDeEstadsticasCombinadas['standing_reach_ft_in'] = BorradorDeEstadsticasCombinadas['standing_reach_ft_in'].fillna(\n",
    "    BorradorDeEstadsticasCombinadas['standing_reach'].apply(lambda x: f\"{int(x // 12)}-{int(x % 12)}\"))\n",
    "\n",
    "# Completar columnas de tiempo de agilidad y press de banca\n",
    "BorradorDeEstadsticasCombinadas['modified_lane_agility_time'].fillna(BorradorDeEstadsticasCombinadas['modified_lane_agility_time'].median(), inplace=True)\n",
    "BorradorDeEstadsticasCombinadas['bench_press'].fillna(BorradorDeEstadsticasCombinadas['bench_press'].median(), inplace=True)\n",
    "\n",
    "# Verificar si quedan valores nulos\n",
    "print(BorradorDeEstadsticasCombinadas.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person_id              0\n",
      "player_name            0\n",
      "season                 0\n",
      "round_number           0\n",
      "round_pick             0\n",
      "overall_pick           0\n",
      "draft_type             0\n",
      "team_id                0\n",
      "team_city              0\n",
      "team_name              0\n",
      "team_abbreviation      0\n",
      "organization           0\n",
      "organization_type      0\n",
      "player_profile_flag    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Rellenar columnas con valores específicos para valores nulos\n",
    "BorradorDeHistoria['organization'].fillna(\"Desconocido\", inplace=True)\n",
    "BorradorDeHistoria['organization_type'].fillna(\"Desconocido\", inplace=True)\n",
    "\n",
    "# Verificar si quedan valores nulos\n",
    "print(BorradorDeHistoria.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game_id       0\n",
      "game_date     0\n",
      "attendance    0\n",
      "game_time     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Rellenar 'attendance' con la mediana de los valores existentes\n",
    "InformacionDelJuego['attendance'].fillna(InformacionDelJuego['attendance'].median(), inplace=True)\n",
    "\n",
    "# Rellenar 'game_time' con un valor nominal indicando desconocido\n",
    "InformacionDelJuego['game_time'].fillna(\"Desconocido\", inplace=True)\n",
    "\n",
    "# Verificar si quedan valores nulos\n",
    "print(InformacionDelJuego.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game_date_est                       0\n",
      "game_sequence                       0\n",
      "game_id                             0\n",
      "game_status_id                      0\n",
      "game_status_text                    0\n",
      "gamecode                            0\n",
      "home_team_id                        0\n",
      "visitor_team_id                     0\n",
      "season                              0\n",
      "live_period                         0\n",
      "live_pc_time                        0\n",
      "natl_tv_broadcaster_abbreviation    0\n",
      "live_period_time_bcast              0\n",
      "wh_status                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Rellenar 'game_sequence' con -1 para indicar un valor nulo\n",
    "ResumendelJuego['game_sequence'].fillna(-1, inplace=True)\n",
    "\n",
    "# Rellenar 'game_status_text' con 'Desconocido'\n",
    "ResumendelJuego['game_status_text'].fillna(\"Desconocido\", inplace=True)\n",
    "\n",
    "# Rellenar 'live_pc_time' con 'Desconocido'\n",
    "ResumendelJuego['live_pc_time'].fillna(\"Desconocido\", inplace=True)\n",
    "\n",
    "# Rellenar 'natl_tv_broadcaster_abbreviation' con 'N/A'\n",
    "ResumendelJuego['natl_tv_broadcaster_abbreviation'].fillna(\"N/A\", inplace=True)\n",
    "\n",
    "# Verificar si quedan valores nulos\n",
    "print(ResumendelJuego.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season_id                     0\n",
      "team_id_home                  0\n",
      "team_abbreviation_home        0\n",
      "team_name_home                0\n",
      "game_id                       0\n",
      "game_date                     0\n",
      "matchup_home                  0\n",
      "wl_home                       0\n",
      "min                           0\n",
      "fgm_home                      0\n",
      "fga_home                      0\n",
      "fg_pct_home                   0\n",
      "fg3m_home                 13218\n",
      "fg3a_home                 18683\n",
      "fg3_pct_home              19074\n",
      "ftm_home                     16\n",
      "fta_home                   3004\n",
      "ft_pct_home                3009\n",
      "oreb_home                     0\n",
      "dreb_home                     0\n",
      "reb_home                      0\n",
      "ast_home                      0\n",
      "stl_home                      0\n",
      "blk_home                      0\n",
      "tov_home                      0\n",
      "pf_home                       0\n",
      "pts_home                      0\n",
      "plus_minus_home               0\n",
      "video_available_home          0\n",
      "team_id_away                  0\n",
      "team_abbreviation_away        0\n",
      "team_name_away                0\n",
      "matchup_away                  0\n",
      "wl_away                       0\n",
      "fgm_away                      0\n",
      "fga_away                      0\n",
      "fg_pct_away                   0\n",
      "fg3m_away                 13218\n",
      "fg3a_away                 18683\n",
      "fg3_pct_away              18962\n",
      "ftm_away                     13\n",
      "fta_away                   3004\n",
      "ft_pct_away                3006\n",
      "oreb_away                     0\n",
      "dreb_away                     0\n",
      "reb_away                      0\n",
      "ast_away                      0\n",
      "stl_away                      0\n",
      "blk_away                      0\n",
      "tov_away                      0\n",
      "pf_away                       0\n",
      "pts_away                      0\n",
      "plus_minus_away               0\n",
      "video_available_away          0\n",
      "season_type                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Rellenar valores nulos para 'wl_home' y 'wl_away'\n",
    "Juego['wl_home'].fillna(\"Desconocido\", inplace=True)\n",
    "Juego['wl_away'].fillna(\"Desconocido\", inplace=True)\n",
    "\n",
    "# Rellenar las estadísticas de tiros\n",
    "Juego['fgm_home'].fillna(0, inplace=True)\n",
    "Juego['fga_home'].fillna(0, inplace=True)\n",
    "Juego['fg_pct_home'].fillna(\"Desconocido\", inplace=True)\n",
    "Juego['fgm_away'].fillna(0, inplace=True)\n",
    "Juego['fga_away'].fillna(0, inplace=True)\n",
    "Juego['fg_pct_away'].fillna(\"Desconocido\", inplace=True)\n",
    "\n",
    "# Rellenar rebotes\n",
    "Juego['oreb_home'].fillna(0, inplace=True)\n",
    "Juego['dreb_home'].fillna(0, inplace=True)\n",
    "Juego['reb_home'].fillna(0, inplace=True)\n",
    "Juego['oreb_away'].fillna(0, inplace=True)\n",
    "Juego['dreb_away'].fillna(0, inplace=True)\n",
    "Juego['reb_away'].fillna(0, inplace=True)\n",
    "\n",
    "# Rellenar asistencias, robos, bloqueos y pérdidas\n",
    "Juego['ast_home'].fillna(0, inplace=True)\n",
    "Juego['stl_home'].fillna(0, inplace=True)\n",
    "Juego['blk_home'].fillna(0, inplace=True)\n",
    "Juego['tov_home'].fillna(0, inplace=True)\n",
    "Juego['ast_away'].fillna(0, inplace=True)\n",
    "Juego['stl_away'].fillna(0, inplace=True)\n",
    "Juego['blk_away'].fillna(0, inplace=True)\n",
    "Juego['tov_away'].fillna(0, inplace=True)\n",
    "\n",
    "# Rellenar faltas personales\n",
    "Juego['pf_home'].fillna(0, inplace=True)\n",
    "Juego['pf_away'].fillna(0, inplace=True)\n",
    "\n",
    "# Verificar si quedan valores nulos\n",
    "print(Juego.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season_id                 0\n",
      "team_id_home              0\n",
      "team_abbreviation_home    0\n",
      "team_name_home            0\n",
      "game_id                   0\n",
      "game_date                 0\n",
      "matchup_home              0\n",
      "wl_home                   0\n",
      "min                       0\n",
      "fgm_home                  0\n",
      "fga_home                  0\n",
      "fg_pct_home               0\n",
      "fg3m_home                 0\n",
      "fg3a_home                 0\n",
      "fg3_pct_home              0\n",
      "ftm_home                  0\n",
      "fta_home                  0\n",
      "ft_pct_home               0\n",
      "oreb_home                 0\n",
      "dreb_home                 0\n",
      "reb_home                  0\n",
      "ast_home                  0\n",
      "stl_home                  0\n",
      "blk_home                  0\n",
      "tov_home                  0\n",
      "pf_home                   0\n",
      "pts_home                  0\n",
      "plus_minus_home           0\n",
      "video_available_home      0\n",
      "team_id_away              0\n",
      "team_abbreviation_away    0\n",
      "team_name_away            0\n",
      "matchup_away              0\n",
      "wl_away                   0\n",
      "fgm_away                  0\n",
      "fga_away                  0\n",
      "fg_pct_away               0\n",
      "fg3m_away                 0\n",
      "fg3a_away                 0\n",
      "fg3_pct_away              0\n",
      "ftm_away                  0\n",
      "fta_away                  0\n",
      "ft_pct_away               0\n",
      "oreb_away                 0\n",
      "dreb_away                 0\n",
      "reb_away                  0\n",
      "ast_away                  0\n",
      "stl_away                  0\n",
      "blk_away                  0\n",
      "tov_away                  0\n",
      "pf_away                   0\n",
      "pts_away                  0\n",
      "plus_minus_away           0\n",
      "video_available_away      0\n",
      "season_type               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Rellenar las estadísticas de tiro de tres puntos\n",
    "Juego['fg3m_home'].fillna(0, inplace=True)\n",
    "Juego['fg3a_home'].fillna(0, inplace=True)\n",
    "Juego['fg3_pct_home'].fillna(0, inplace=True)  # O \"Desconocido\" si prefieres\n",
    "Juego['fg3m_away'].fillna(0, inplace=True)\n",
    "Juego['fg3a_away'].fillna(0, inplace=True)\n",
    "Juego['fg3_pct_away'].fillna(0, inplace=True)  # O \"Desconocido\"\n",
    "\n",
    "# Rellenar los tiros libres\n",
    "Juego['ftm_home'].fillna(0, inplace=True)\n",
    "Juego['fta_home'].fillna(0, inplace=True)\n",
    "Juego['ft_pct_home'].fillna(0, inplace=True)  # O \"Desconocido\"\n",
    "Juego['ftm_away'].fillna(0, inplace=True)\n",
    "Juego['fta_away'].fillna(0, inplace=True)\n",
    "Juego['ft_pct_away'].fillna(0, inplace=True)  # O \"Desconocido\"\n",
    "\n",
    "# Verificar si quedan valores nulos\n",
    "print(Juego.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team_id               0\n",
      "abbreviation          0\n",
      "nickname              0\n",
      "yearfounded           0\n",
      "city                  0\n",
      "arena                 0\n",
      "arenacapacity         0\n",
      "owner                 0\n",
      "generalmanager        0\n",
      "headcoach             0\n",
      "dleagueaffiliation    0\n",
      "facebook              0\n",
      "instagram             0\n",
      "twitter               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Rellenar los valores nulos en 'arenacapacity' con la mediana\n",
    "DetallesDelEquipo['arenacapacity'].fillna(DetallesDelEquipo['arenacapacity'].median(), inplace=True)\n",
    "\n",
    "# Rellenar el valor nulo en 'headcoach' con 'Desconocido'\n",
    "DetallesDelEquipo['headcoach'].fillna('Desconocido', inplace=True)\n",
    "\n",
    "# Verificar si quedan valores nulos\n",
    "print(DetallesDelEquipo.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   person_id first_name     last_name   display_first_last  \\\n",
      "0      76001       Alaa     Abdelnaby       Alaa Abdelnaby   \n",
      "1      76003     Kareem  Abdul-Jabbar  Kareem Abdul-Jabbar   \n",
      "2       1505      Tariq   Abdul-Wahad    Tariq Abdul-Wahad   \n",
      "3        949    Shareef   Abdur-Rahim  Shareef Abdur-Rahim   \n",
      "4      76005        Tom     Abernethy        Tom Abernethy   \n",
      "\n",
      "  display_last_comma_first  display_fi_last          player_slug  \\\n",
      "0          Abdelnaby, Alaa     A. Abdelnaby       alaa-abdelnaby   \n",
      "1     Abdul-Jabbar, Kareem  K. Abdul-Jabbar  kareem-abdul-jabbar   \n",
      "2       Abdul-Wahad, Tariq   T. Abdul-Wahad    tariq-abdul-wahad   \n",
      "3     Abdur-Rahim, Shareef   S. Abdur-Rahim  shareef-abdur-rahim   \n",
      "4           Abernethy, Tom     T. Abernethy        tom-abernethy   \n",
      "\n",
      "             birthdate          school country  ...  \\\n",
      "0  1968-06-24 00:00:00            Duke     USA  ...   \n",
      "1  1947-04-16 00:00:00            UCLA     USA  ...   \n",
      "2  1974-11-03 00:00:00  San Jose State  France  ...   \n",
      "3  1976-12-11 00:00:00      California     USA  ...   \n",
      "4  1954-05-06 00:00:00         Indiana     USA  ...   \n",
      "\n",
      "                    playercode  from_year  to_year  dleague_flag nba_flag  \\\n",
      "0       HISTADD_alaa_abdelnaby     1990.0   1994.0             N        Y   \n",
      "1  HISTADD_kareem_abdul-jabbar     1969.0   1988.0             N        Y   \n",
      "2            tariq_abdul-wahad     1997.0   2003.0             N        Y   \n",
      "3          shareef_abdur-rahim     1996.0   2007.0             N        Y   \n",
      "4        HISTADD_tom_abernethy     1976.0   1980.0             N        Y   \n",
      "\n",
      "  games_played_flag draft_year draft_round  draft_number greatest_75_flag  \n",
      "0                 Y       1990           1            25                N  \n",
      "1                 Y       1969           1             1                Y  \n",
      "2                 Y       1997           1            11                N  \n",
      "3                 Y       1996           1             3                N  \n",
      "4                 Y       1976           3            43                N  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(InformacionComunDelJugador.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season  player_id first_name   last_name        player_name position  \\\n",
      "0    2001      12033       Adam  Allenspach    Adam Allenspach        C   \n",
      "1    2001       2240    Gilbert      Arenas     Gilbert Arenas       SG   \n",
      "2    2001       2220    Brandon   Armstrong  Brandon Armstrong       SG   \n",
      "3    2001       2203      Shane     Battier      Shane Battier    SF-PF   \n",
      "4    2001      12034     Cookie     Belcher     Cookie Belcher    SG-PG   \n",
      "\n",
      "   height_wo_shoes height_wo_shoes_ft_in  height_w_shoes height_w_shoes_ft_in  \\\n",
      "0            83.50             6' 11.5''            79.0                  6-7   \n",
      "1            74.25             6' 2.25''            79.0                  6-7   \n",
      "2            75.50              6' 3.5''            79.0                  6-7   \n",
      "3            80.25             6' 8.25''            79.0                  6-7   \n",
      "4            75.00                6' 3''            79.0                  6-7   \n",
      "\n",
      "   ...  spot_nba_break_right  spot_nba_corner_right  \\\n",
      "0  ...                     0                      0   \n",
      "1  ...                     0                      0   \n",
      "2  ...                     0                      0   \n",
      "3  ...                     0                      0   \n",
      "4  ...                     0                      0   \n",
      "\n",
      "  off_drib_fifteen_break_left  off_drib_fifteen_top_key  \\\n",
      "0                           0                         0   \n",
      "1                           0                         0   \n",
      "2                           0                         0   \n",
      "3                           0                         0   \n",
      "4                           0                         0   \n",
      "\n",
      "  off_drib_fifteen_break_right  off_drib_college_break_left  \\\n",
      "0                            0                            0   \n",
      "1                            0                            0   \n",
      "2                            0                            0   \n",
      "3                            0                            0   \n",
      "4                            0                            0   \n",
      "\n",
      "   off_drib_college_top_key  off_drib_college_break_right  on_move_fifteen  \\\n",
      "0                         0                             0                0   \n",
      "1                         0                             0                0   \n",
      "2                         0                             0                0   \n",
      "3                         0                             0                0   \n",
      "4                         0                             0                0   \n",
      "\n",
      "   on_move_college  \n",
      "0                0  \n",
      "1                0  \n",
      "2                0  \n",
      "3                0  \n",
      "4                0  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "print(BorradorDeEstadsticasCombinadas.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BorradorDeEstadsticasCombinadas', 'BorradorDeHistoria', 'DetallesDelEquipo', 'HistoriaDelEquipo', 'In', 'InformacionComunDelJugador', 'InformacionDelJuego', 'Juego', 'JuegoPorJuego', 'Jugador', 'JugadoresInactivos', 'Oficiales', 'OtrasEstadisticas', 'Out', 'PuntuacionDeLinea', 'ResumendelJuego', '_', '_10', '_11', '_12', '_13', '_14', '_15', '_16', '_17', '_18', '_20', '_21', '_22', '_23', '_24', '_25', '_26', '_27', '_28', '_29', '_30', '_31', '_32', '_4', '_5', '_6', '_7', '_8', '_9', '__', '___', '__builtin__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', '__vsc_ipynb_file__', '_dh', '_i', '_i1', '_i10', '_i11', '_i12', '_i13', '_i14', '_i15', '_i16', '_i17', '_i18', '_i19', '_i2', '_i20', '_i21', '_i22', '_i23', '_i24', '_i25', '_i26', '_i27', '_i28', '_i29', '_i3', '_i30', '_i31', '_i32', '_i33', '_i34', '_i35', '_i36', '_i37', '_i38', '_i39', '_i4', '_i40', '_i41', '_i42', '_i43', '_i44', '_i45', '_i5', '_i6', '_i7', '_i8', '_i9', '_ih', '_ii', '_iii', '_oh', 'cols_tiro', 'convertir_altura_a_pulgadas', 'create_engine', 'df', 'dtype_sql', 'duplicados', 'engine', 'exit', 'file_path', 'get_ipython', 'np', 'open', 'pd', 'plt', 'pyodbc', 'quit', 'sns', 'text', 'types', 'warnings']\n"
     ]
    }
   ],
   "source": [
    "print(dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4171 entries, 0 to 4170\n",
      "Data columns (total 33 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   person_id                         4171 non-null   int64  \n",
      " 1   first_name                        4171 non-null   object \n",
      " 2   last_name                         4171 non-null   object \n",
      " 3   display_first_last                4171 non-null   object \n",
      " 4   display_last_comma_first          4171 non-null   object \n",
      " 5   display_fi_last                   4171 non-null   object \n",
      " 6   player_slug                       4171 non-null   object \n",
      " 7   birthdate                         4171 non-null   object \n",
      " 8   school                            4171 non-null   object \n",
      " 9   country                           4171 non-null   object \n",
      " 10  last_affiliation                  4171 non-null   object \n",
      " 11  height                            4171 non-null   float64\n",
      " 12  weight                            4171 non-null   float64\n",
      " 13  season_exp                        4171 non-null   float64\n",
      " 14  jersey                            4171 non-null   object \n",
      " 15  position                          4171 non-null   object \n",
      " 16  rosterstatus                      4171 non-null   object \n",
      " 17  games_played_current_season_flag  4171 non-null   object \n",
      " 18  team_id                           4171 non-null   int64  \n",
      " 19  team_name                         4171 non-null   object \n",
      " 20  team_abbreviation                 4171 non-null   object \n",
      " 21  team_code                         4171 non-null   object \n",
      " 22  team_city                         4171 non-null   object \n",
      " 23  playercode                        4171 non-null   object \n",
      " 24  from_year                         4171 non-null   float64\n",
      " 25  to_year                           4171 non-null   float64\n",
      " 26  dleague_flag                      4171 non-null   object \n",
      " 27  nba_flag                          4171 non-null   object \n",
      " 28  games_played_flag                 4171 non-null   object \n",
      " 29  draft_year                        4171 non-null   object \n",
      " 30  draft_round                       4171 non-null   object \n",
      " 31  draft_number                      4171 non-null   object \n",
      " 32  greatest_75_flag                  4171 non-null   object \n",
      "dtypes: float64(5), int64(2), object(26)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(InformacionComunDelJugador.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversiones automáticas aplicadas en InformacionComunDelJugador\n",
      "Conversiones automáticas aplicadas en BorradorDeEstadsticasCombinadas\n",
      "Conversiones automáticas aplicadas en BorradorDeHistoria\n",
      "Conversiones automáticas aplicadas en InformacionDelJuego\n",
      "Conversiones automáticas aplicadas en ResumendelJuego\n",
      "Conversiones automáticas aplicadas en Juego\n",
      "Conversiones automáticas aplicadas en JugadoresInactivos\n",
      "Conversiones automáticas aplicadas en PuntuacionDeLinea\n",
      "Conversiones automáticas aplicadas en Oficiales\n",
      "Conversiones automáticas aplicadas en OtrasEstadisticas\n",
      "Conversiones automáticas aplicadas en JuegoPorJuego\n",
      "Conversiones automáticas aplicadas en Jugador\n",
      "Conversiones automáticas aplicadas en DetallesDelEquipo\n",
      "Conversiones automáticas aplicadas en HistoriaDelEquipo\n"
     ]
    }
   ],
   "source": [
    "# Diccionario con todos los DataFrames\n",
    "dataframes = {\n",
    "    \"InformacionComunDelJugador\": InformacionComunDelJugador,\n",
    "    \"BorradorDeEstadsticasCombinadas\": BorradorDeEstadsticasCombinadas,\n",
    "    \"BorradorDeHistoria\": BorradorDeHistoria,\n",
    "    \"InformacionDelJuego\": InformacionDelJuego,\n",
    "    \"ResumendelJuego\": ResumendelJuego,\n",
    "    \"Juego\": Juego,\n",
    "    \"JugadoresInactivos\": JugadoresInactivos,\n",
    "    \"PuntuacionDeLinea\": PuntuacionDeLinea,\n",
    "    \"Oficiales\": Oficiales,\n",
    "    \"OtrasEstadisticas\": OtrasEstadisticas,\n",
    "    \"JuegoPorJuego\": JuegoPorJuego,\n",
    "    \"Jugador\": Jugador,\n",
    "    \"DetallesDelEquipo\": DetallesDelEquipo,\n",
    "    \"HistoriaDelEquipo\": HistoriaDelEquipo\n",
    "}\n",
    "\n",
    "# Iterar sobre cada DataFrame y aplicar conversiones basadas en los tipos de datos\n",
    "for name, df in dataframes.items():\n",
    "    # Detectar y convertir automáticamente columnas con fechas (formato de texto)\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        try:\n",
    "            # Intentar convertir la columna a formato de fecha\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        except:\n",
    "            pass  # Si no se puede convertir, sigue al siguiente\n",
    "    \n",
    "    # Detectar y convertir automáticamente columnas numéricas\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        try:\n",
    "            # Intentar convertir la columna a formato numérico\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        except:\n",
    "            pass  # Si no se puede convertir, sigue al siguiente\n",
    "    \n",
    "    # Imprimir un mensaje para confirmar que las conversiones se aplicaron\n",
    "    print(f\"Conversiones automáticas aplicadas en {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los DataFrames se han guardado correctamente como archivos CSV.\n"
     ]
    }
   ],
   "source": [
    "for df_name, df in dataframes.items():\n",
    "    df.to_csv(f\"{df_name}_transformado.csv\", index=False)\n",
    "\n",
    "print(\"Todos los DataFrames se han guardado correctamente como archivos CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame cargado: BorradorDeEstadsticasCombinadas, con 1202 filas y 47 columnas.\n",
      "DataFrame cargado: BorradorDeHistoria, con 7990 filas y 14 columnas.\n",
      "DataFrame cargado: DetallesDelEquipo, con 25 filas y 14 columnas.\n",
      "DataFrame cargado: HistoriaDelEquipo, con 52 filas y 5 columnas.\n",
      "DataFrame cargado: InformacionComunDelJugador, con 4171 filas y 33 columnas.\n",
      "DataFrame cargado: InformacionDelJuego, con 58053 filas y 4 columnas.\n",
      "DataFrame cargado: JuegoPorJuego, con 13592899 filas y 34 columnas.\n",
      "DataFrame cargado: Juego, con 65698 filas y 55 columnas.\n",
      "DataFrame cargado: JugadoresInactivos, con 110191 filas y 9 columnas.\n",
      "DataFrame cargado: Jugador, con 4831 filas y 5 columnas.\n",
      "DataFrame cargado: Oficiales, con 70971 filas y 5 columnas.\n",
      "DataFrame cargado: OtrasEstadisticas, con 28271 filas y 26 columnas.\n",
      "DataFrame cargado: PuntuacionDeLinea, con 58053 filas y 43 columnas.\n",
      "DataFrame cargado: ResumendelJuego, con 58110 filas y 14 columnas.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Buscar todos los archivos CSV en el directorio actual que tengan el sufijo '_transformado.csv'\n",
    "archivos_csv = glob.glob(\"*_transformado.csv\")\n",
    "\n",
    "# Diccionario para almacenar los DataFrames cargados\n",
    "dataframes_cargados = {}\n",
    "\n",
    "# Cargar cada archivo CSV\n",
    "for archivo in archivos_csv:\n",
    "    # Extraer el nombre del archivo sin la extensión\n",
    "    df_name = archivo.split(\"_transformado.csv\")[0]\n",
    "    # Cargar el DataFrame\n",
    "    df = pd.read_csv(archivo)\n",
    "    dataframes_cargados[df_name] = df\n",
    "\n",
    "# Verificar que los DataFrames se hayan cargado correctamente\n",
    "for df_name, df in dataframes_cargados.items():\n",
    "    print(f\"DataFrame cargado: {df_name}, con {df.shape[0]} filas y {df.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron duplicados en la columna 'player_id':\n",
      "      season  player_id  first_name  last_name  player_name  position  \\\n",
      "31      2001         -1         NaN        NaN          NaN       NaN   \n",
      "131     2004         -1         NaN        NaN          NaN       NaN   \n",
      "200     2005         -1         NaN        NaN          NaN       NaN   \n",
      "784     2017    1628959         NaN        NaN          NaN       NaN   \n",
      "801     2017    1628977         NaN        NaN          NaN       NaN   \n",
      "815     2017    1628992         NaN        NaN          NaN       NaN   \n",
      "827     2017    1629004         NaN        NaN          NaN       NaN   \n",
      "840     2017    1629021         NaN        NaN          NaN       NaN   \n",
      "847     2018    1628959         NaN        NaN          NaN       NaN   \n",
      "850     2018    1628962         NaN        NaN          NaN       NaN   \n",
      "855     2018    1628968         NaN        NaN          NaN       NaN   \n",
      "864     2018    1628977         NaN        NaN          NaN       NaN   \n",
      "869     2018    1628981         NaN        NaN          NaN       NaN   \n",
      "875     2018    1628986         NaN        NaN          NaN       NaN   \n",
      "880     2018    1628992         NaN        NaN          NaN       NaN   \n",
      "886     2018    1628998         NaN        NaN          NaN       NaN   \n",
      "892     2018    1629004         NaN        NaN          NaN       NaN   \n",
      "896     2018    1629007         NaN        NaN          NaN       NaN   \n",
      "909     2018    1629021         NaN        NaN          NaN       NaN   \n",
      "911     2018    1629023         NaN        NaN          NaN       NaN   \n",
      "913     2018    1629025         NaN        NaN          NaN       NaN   \n",
      "922     2019    1628968         NaN        NaN          NaN       NaN   \n",
      "933     2019    1629653         NaN        NaN          NaN       NaN   \n",
      "936     2019    1628981         NaN        NaN          NaN       NaN   \n",
      "941     2019    1628986         NaN        NaN          NaN       NaN   \n",
      "960     2019    1628998         NaN        NaN          NaN       NaN   \n",
      "966     2019    1629670         NaN        NaN          NaN       NaN   \n",
      "971     2019    1629617         NaN        NaN          NaN       NaN   \n",
      "974     2019    1629007         NaN        NaN          NaN       NaN   \n",
      "984     2019    1629681         NaN        NaN          NaN       NaN   \n",
      "985     2019    1629023         NaN        NaN          NaN       NaN   \n",
      "989     2019    1629025         NaN        NaN          NaN       NaN   \n",
      "995     2020    1628962         NaN        NaN          NaN       NaN   \n",
      "999     2020    1629653         NaN        NaN          NaN       NaN   \n",
      "1018    2020    1629670         NaN        NaN          NaN       NaN   \n",
      "1019    2020    1629617         NaN        NaN          NaN       NaN   \n",
      "1032    2020    1629681         NaN        NaN          NaN       NaN   \n",
      "1070    2022    1631218         NaN        NaN          NaN       NaN   \n",
      "1085    2022    1631159         NaN        NaN          NaN       NaN   \n",
      "1099    2022    1631204         NaN        NaN          NaN       NaN   \n",
      "1102    2022    1631173         NaN        NaN          NaN       NaN   \n",
      "1106    2022    1631124         NaN        NaN          NaN       NaN   \n",
      "1108    2022    1631166         NaN        NaN          NaN       NaN   \n",
      "1119    2022    1630592         NaN        NaN          NaN       NaN   \n",
      "1150    2023    1631218         NaN        NaN          NaN       NaN   \n",
      "1166    2023    1631159         NaN        NaN          NaN       NaN   \n",
      "1179    2023    1631204         NaN        NaN          NaN       NaN   \n",
      "1184    2023    1631173         NaN        NaN          NaN       NaN   \n",
      "1186    2023    1631124         NaN        NaN          NaN       NaN   \n",
      "1189    2023    1631166         NaN        NaN          NaN       NaN   \n",
      "1200    2023    1630592         NaN        NaN          NaN       NaN   \n",
      "\n",
      "      height_wo_shoes  height_wo_shoes_ft_in  height_w_shoes  \\\n",
      "31              69.75                    NaN           79.00   \n",
      "131             81.25                    NaN           82.75   \n",
      "200             71.50                    NaN           72.75   \n",
      "784             74.50                    NaN           75.75   \n",
      "801             75.75                    NaN           77.00   \n",
      "815             77.75                    NaN           79.00   \n",
      "827             78.50                    NaN           79.50   \n",
      "840             82.00                    NaN           83.25   \n",
      "847             74.75                    NaN           76.25   \n",
      "850             82.00                    NaN           84.25   \n",
      "855             78.25                    NaN           79.50   \n",
      "864             76.25                    NaN           78.00   \n",
      "869             80.75                    NaN           81.75   \n",
      "875             73.50                    NaN           74.75   \n",
      "880             78.00                    NaN           78.75   \n",
      "886             76.75                    NaN           78.00   \n",
      "892             78.50                    NaN           79.75   \n",
      "896             82.00                    NaN           83.50   \n",
      "909             82.50                    NaN           83.50   \n",
      "911             78.50                    NaN           80.00   \n",
      "913             78.50                    NaN           79.50   \n",
      "922             78.25                    NaN           79.50   \n",
      "933             72.00                    NaN           74.00   \n",
      "936             80.75                    NaN           82.25   \n",
      "941             73.50                    NaN           75.00   \n",
      "960             76.75                    NaN           77.50   \n",
      "966             77.75                    NaN           79.50   \n",
      "971             80.00                    NaN           81.25   \n",
      "974             81.75                    NaN           83.00   \n",
      "984             77.75                    NaN           79.00   \n",
      "985             78.50                    NaN           80.00   \n",
      "989             78.25                    NaN           79.75   \n",
      "995             82.00                    NaN           83.50   \n",
      "999             72.50                    NaN           73.70   \n",
      "1018            77.75                    NaN           79.00   \n",
      "1019            80.25                    NaN           81.20   \n",
      "1032            80.75                    NaN           82.00   \n",
      "1070            77.75                    NaN           79.00   \n",
      "1085            80.50                    NaN           82.00   \n",
      "1099            77.75                    NaN           79.00   \n",
      "1102            74.25                    NaN           75.75   \n",
      "1106            77.75                    NaN           79.00   \n",
      "1108            80.25                    NaN           81.25   \n",
      "1119            77.75                    NaN           79.00   \n",
      "1150            80.25                    NaN           79.00   \n",
      "1166            81.25                    NaN           79.00   \n",
      "1179            73.25                    NaN           79.00   \n",
      "1184            74.50                    NaN           79.00   \n",
      "1186            78.00                    NaN           79.00   \n",
      "1189            80.75                    NaN           79.00   \n",
      "1200            77.50                    NaN           79.00   \n",
      "\n",
      "      height_w_shoes_ft_in  ...  spot_nba_break_right  spot_nba_corner_right  \\\n",
      "31                     NaN  ...            1970-01-01             1970-01-01   \n",
      "131                    NaN  ...            1970-01-01             1970-01-01   \n",
      "200                    NaN  ...            1970-01-01             1970-01-01   \n",
      "784                    NaN  ...                   NaN                    NaN   \n",
      "801                    NaN  ...            1970-01-01             1970-01-01   \n",
      "815                    NaN  ...                   NaN                    NaN   \n",
      "827                    NaN  ...                   NaN                    NaN   \n",
      "840                    NaN  ...                   NaN                    NaN   \n",
      "847                    NaN  ...                   NaN                    NaN   \n",
      "850                    NaN  ...            1970-01-01             1970-01-01   \n",
      "855                    NaN  ...                   NaN                    NaN   \n",
      "864                    NaN  ...            1970-01-01             1970-01-01   \n",
      "869                    NaN  ...                   NaN                    NaN   \n",
      "875                    NaN  ...                   NaN                    NaN   \n",
      "880                    NaN  ...            1970-01-01             1970-01-01   \n",
      "886                    NaN  ...                   NaN                    NaN   \n",
      "892                    NaN  ...                   NaN                    NaN   \n",
      "896                    NaN  ...                   NaN                    NaN   \n",
      "909                    NaN  ...            1970-01-01             1970-01-01   \n",
      "911                    NaN  ...                   NaN                    NaN   \n",
      "913                    NaN  ...                   NaN                    NaN   \n",
      "922                    NaN  ...            1970-01-01             1970-01-01   \n",
      "933                    NaN  ...                   NaN                    NaN   \n",
      "936                    NaN  ...            1970-01-01             1970-01-01   \n",
      "941                    NaN  ...                   NaN                    NaN   \n",
      "960                    NaN  ...                   NaN                    NaN   \n",
      "966                    NaN  ...            1970-01-01             1970-01-01   \n",
      "971                    NaN  ...                   NaN                    NaN   \n",
      "974                    NaN  ...            1970-01-01             1970-01-01   \n",
      "984                    NaN  ...            1970-01-01             1970-01-01   \n",
      "985                    NaN  ...            1970-01-01             1970-01-01   \n",
      "989                    NaN  ...                   NaN                    NaN   \n",
      "995                    NaN  ...            1970-01-01             1970-01-01   \n",
      "999                    NaN  ...            1970-01-01             1970-01-01   \n",
      "1018                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1019                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1032                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1070                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1085                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1099                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1102                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1106                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1108                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1119                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1150                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1166                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1179                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1184                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1186                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1189                   NaN  ...            1970-01-01             1970-01-01   \n",
      "1200                   NaN  ...            1970-01-01             1970-01-01   \n",
      "\n",
      "      off_drib_fifteen_break_left  off_drib_fifteen_top_key  \\\n",
      "31                     1970-01-01                1970-01-01   \n",
      "131                    1970-01-01                1970-01-01   \n",
      "200                    1970-01-01                1970-01-01   \n",
      "784                           NaN                       NaN   \n",
      "801                    1970-01-01                1970-01-01   \n",
      "815                           NaN                       NaN   \n",
      "827                           NaN                       NaN   \n",
      "840                    1970-01-01                1970-01-01   \n",
      "847                           NaN                       NaN   \n",
      "850                    1970-01-01                1970-01-01   \n",
      "855                           NaN                       NaN   \n",
      "864                    1970-01-01                1970-01-01   \n",
      "869                           NaN                       NaN   \n",
      "875                           NaN                       NaN   \n",
      "880                    1970-01-01                1970-01-01   \n",
      "886                           NaN                       NaN   \n",
      "892                           NaN                       NaN   \n",
      "896                           NaN                       NaN   \n",
      "909                    1970-01-01                1970-01-01   \n",
      "911                           NaN                       NaN   \n",
      "913                           NaN                       NaN   \n",
      "922                    1970-01-01                1970-01-01   \n",
      "933                           NaN                       NaN   \n",
      "936                    1970-01-01                1970-01-01   \n",
      "941                    1970-01-01                1970-01-01   \n",
      "960                           NaN                       NaN   \n",
      "966                    1970-01-01                1970-01-01   \n",
      "971                           NaN                       NaN   \n",
      "974                    1970-01-01                1970-01-01   \n",
      "984                    1970-01-01                1970-01-01   \n",
      "985                    1970-01-01                1970-01-01   \n",
      "989                           NaN                       NaN   \n",
      "995                    1970-01-01                1970-01-01   \n",
      "999                    1970-01-01                1970-01-01   \n",
      "1018                   1970-01-01                1970-01-01   \n",
      "1019                   1970-01-01                1970-01-01   \n",
      "1032                   1970-01-01                1970-01-01   \n",
      "1070                   1970-01-01                1970-01-01   \n",
      "1085                   1970-01-01                1970-01-01   \n",
      "1099                   1970-01-01                1970-01-01   \n",
      "1102                   1970-01-01                1970-01-01   \n",
      "1106                   1970-01-01                1970-01-01   \n",
      "1108                   1970-01-01                1970-01-01   \n",
      "1119                   1970-01-01                1970-01-01   \n",
      "1150                   1970-01-01                1970-01-01   \n",
      "1166                   1970-01-01                1970-01-01   \n",
      "1179                   1970-01-01                1970-01-01   \n",
      "1184                   1970-01-01                1970-01-01   \n",
      "1186                   1970-01-01                1970-01-01   \n",
      "1189                   1970-01-01                1970-01-01   \n",
      "1200                   1970-01-01                1970-01-01   \n",
      "\n",
      "      off_drib_fifteen_break_right  off_drib_college_break_left  \\\n",
      "31                      1970-01-01                   1970-01-01   \n",
      "131                     1970-01-01                   1970-01-01   \n",
      "200                     1970-01-01                   1970-01-01   \n",
      "784                            NaN                   1970-01-01   \n",
      "801                     1970-01-01                   1970-01-01   \n",
      "815                            NaN                   1970-01-01   \n",
      "827                            NaN                   1970-01-01   \n",
      "840                     1970-01-01                          NaN   \n",
      "847                            NaN                   1970-01-01   \n",
      "850                     1970-01-01                   1970-01-01   \n",
      "855                            NaN                   1970-01-01   \n",
      "864                     1970-01-01                   1970-01-01   \n",
      "869                            NaN                          NaN   \n",
      "875                            NaN                   1970-01-01   \n",
      "880                     1970-01-01                   1970-01-01   \n",
      "886                            NaN                          NaN   \n",
      "892                            NaN                   1970-01-01   \n",
      "896                            NaN                   1970-01-01   \n",
      "909                     1970-01-01                   1970-01-01   \n",
      "911                            NaN                   1970-01-01   \n",
      "913                            NaN                   1970-01-01   \n",
      "922                     1970-01-01                   1970-01-01   \n",
      "933                            NaN                   1970-01-01   \n",
      "936                     1970-01-01                   1970-01-01   \n",
      "941                     1970-01-01                          NaN   \n",
      "960                            NaN                   1970-01-01   \n",
      "966                     1970-01-01                   1970-01-01   \n",
      "971                            NaN                   1970-01-01   \n",
      "974                     1970-01-01                   1970-01-01   \n",
      "984                     1970-01-01                   1970-01-01   \n",
      "985                     1970-01-01                   1970-01-01   \n",
      "989                            NaN                   1970-01-01   \n",
      "995                     1970-01-01                   1970-01-01   \n",
      "999                     1970-01-01                   1970-01-01   \n",
      "1018                    1970-01-01                   1970-01-01   \n",
      "1019                    1970-01-01                   1970-01-01   \n",
      "1032                    1970-01-01                   1970-01-01   \n",
      "1070                    1970-01-01                   1970-01-01   \n",
      "1085                    1970-01-01                          NaN   \n",
      "1099                    1970-01-01                   1970-01-01   \n",
      "1102                    1970-01-01                          NaN   \n",
      "1106                    1970-01-01                          NaN   \n",
      "1108                    1970-01-01                          NaN   \n",
      "1119                    1970-01-01                   1970-01-01   \n",
      "1150                    1970-01-01                          NaN   \n",
      "1166                    1970-01-01                          NaN   \n",
      "1179                    1970-01-01                          NaN   \n",
      "1184                    1970-01-01                          NaN   \n",
      "1186                    1970-01-01                          NaN   \n",
      "1189                    1970-01-01                          NaN   \n",
      "1200                    1970-01-01                          NaN   \n",
      "\n",
      "      off_drib_college_top_key  off_drib_college_break_right  on_move_fifteen  \\\n",
      "31                  1970-01-01                    1970-01-01       1970-01-01   \n",
      "131                 1970-01-01                    1970-01-01       1970-01-01   \n",
      "200                 1970-01-01                    1970-01-01       1970-01-01   \n",
      "784                 1970-01-01                    1970-01-01              NaN   \n",
      "801                 1970-01-01                    1970-01-01       1970-01-01   \n",
      "815                 1970-01-01                    1970-01-01              NaN   \n",
      "827                 1970-01-01                    1970-01-01              NaN   \n",
      "840                        NaN                           NaN       1970-01-01   \n",
      "847                 1970-01-01                    1970-01-01              NaN   \n",
      "850                 1970-01-01                    1970-01-01       1970-01-01   \n",
      "855                 1970-01-01                    1970-01-01              NaN   \n",
      "864                 1970-01-01                    1970-01-01       1970-01-01   \n",
      "869                        NaN                           NaN              NaN   \n",
      "875                 1970-01-01                    1970-01-01              NaN   \n",
      "880                 1970-01-01                    1970-01-01       1970-01-01   \n",
      "886                        NaN                           NaN              NaN   \n",
      "892                 1970-01-01                    1970-01-01       1970-01-01   \n",
      "896                 1970-01-01                    1970-01-01              NaN   \n",
      "909                 1970-01-01                    1970-01-01       1970-01-01   \n",
      "911                 1970-01-01                    1970-01-01              NaN   \n",
      "913                 1970-01-01                    1970-01-01              NaN   \n",
      "922                 1970-01-01                    1970-01-01              NaN   \n",
      "933                 1970-01-01                    1970-01-01              NaN   \n",
      "936                 1970-01-01                    1970-01-01              NaN   \n",
      "941                        NaN                           NaN              NaN   \n",
      "960                 1970-01-01                    1970-01-01              NaN   \n",
      "966                 1970-01-01                    1970-01-01       1970-01-01   \n",
      "971                 1970-01-01                    1970-01-01              NaN   \n",
      "974                 1970-01-01                    1970-01-01       1970-01-01   \n",
      "984                 1970-01-01                    1970-01-01       1970-01-01   \n",
      "985                 1970-01-01                    1970-01-01       1970-01-01   \n",
      "989                 1970-01-01                    1970-01-01              NaN   \n",
      "995                 1970-01-01                    1970-01-01       1970-01-01   \n",
      "999                 1970-01-01                    1970-01-01       1970-01-01   \n",
      "1018                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1019                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1032                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1070                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1085                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1099                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1102                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1106                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1108                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1119                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1150                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1166                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1179                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1184                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1186                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1189                1970-01-01                    1970-01-01       1970-01-01   \n",
      "1200                1970-01-01                    1970-01-01       1970-01-01   \n",
      "\n",
      "      on_move_college  \n",
      "31         1970-01-01  \n",
      "131        1970-01-01  \n",
      "200        1970-01-01  \n",
      "784        1970-01-01  \n",
      "801        1970-01-01  \n",
      "815        1970-01-01  \n",
      "827        1970-01-01  \n",
      "840               NaN  \n",
      "847        1970-01-01  \n",
      "850        1970-01-01  \n",
      "855        1970-01-01  \n",
      "864        1970-01-01  \n",
      "869        1970-01-01  \n",
      "875        1970-01-01  \n",
      "880        1970-01-01  \n",
      "886        1970-01-01  \n",
      "892        1970-01-01  \n",
      "896               NaN  \n",
      "909        1970-01-01  \n",
      "911        1970-01-01  \n",
      "913        1970-01-01  \n",
      "922        1970-01-01  \n",
      "933        1970-01-01  \n",
      "936        1970-01-01  \n",
      "941        1970-01-01  \n",
      "960        1970-01-01  \n",
      "966        1970-01-01  \n",
      "971        1970-01-01  \n",
      "974        1970-01-01  \n",
      "984        1970-01-01  \n",
      "985        1970-01-01  \n",
      "989        1970-01-01  \n",
      "995        1970-01-01  \n",
      "999        1970-01-01  \n",
      "1018       1970-01-01  \n",
      "1019       1970-01-01  \n",
      "1032       1970-01-01  \n",
      "1070       1970-01-01  \n",
      "1085       1970-01-01  \n",
      "1099       1970-01-01  \n",
      "1102              NaN  \n",
      "1106              NaN  \n",
      "1108              NaN  \n",
      "1119       1970-01-01  \n",
      "1150              NaN  \n",
      "1166              NaN  \n",
      "1179              NaN  \n",
      "1184              NaN  \n",
      "1186              NaN  \n",
      "1189              NaN  \n",
      "1200              NaN  \n",
      "\n",
      "[51 rows x 47 columns]\n",
      "Duplicados eliminados.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\2599570557.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  BorradorDeEstadsticasCombinadas['player_id'].fillna('0', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla BorradorDeEstadsticasCombinadas en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "BorradorDeEstadsticasCombinadas = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\BorradorDeEstadsticasCombinadas_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'InventarioID'\n",
    "if 'player_id' in BorradorDeEstadsticasCombinadas.columns:\n",
    "    duplicados = BorradorDeEstadsticasCombinadas[BorradorDeEstadsticasCombinadas.duplicated(subset=['player_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'player_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        BorradorDeEstadsticasCombinadas = BorradorDeEstadsticasCombinadas.drop_duplicates(subset=['player_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'InventarioID' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'InventarioID' no tenga valores nulos y convertir a string\n",
    "BorradorDeEstadsticasCombinadas['player_id'].fillna('0', inplace=True)\n",
    "BorradorDeEstadsticasCombinadas['player_id'] = BorradorDeEstadsticasCombinadas['player_id'].astype(str)\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "dtype_sql = {\n",
    "    'season': types.INTEGER,\n",
    "    'player_id': types.INTEGER,\n",
    "    'first_name': types.VARCHAR(length=50),\n",
    "    'last_name': types.VARCHAR(length=50),\n",
    "    'player_name': types.VARCHAR(length=100),\n",
    "    'position': types.VARCHAR(length=10),\n",
    "    'height_wo_shoes': types.FLOAT,\n",
    "    'height_wo_shoes_ft_in': types.VARCHAR(length=10),\n",
    "    'height_w_shoes': types.FLOAT,\n",
    "    'height_w_shoes_ft_in': types.VARCHAR(length=10),\n",
    "    'weight': types.FLOAT,\n",
    "    'wingspan': types.FLOAT,\n",
    "    'wingspan_ft_in': types.VARCHAR(length=10),\n",
    "    'standing_reach': types.FLOAT,\n",
    "    'standing_reach_ft_in': types.VARCHAR(length=10),\n",
    "    'body_fat_pct': types.FLOAT,\n",
    "    'hand_length': types.FLOAT,\n",
    "    'hand_width': types.FLOAT,\n",
    "    'standing_vertical_leap': types.FLOAT,\n",
    "    'max_vertical_leap': types.FLOAT,\n",
    "    'lane_agility_time': types.FLOAT,\n",
    "    'modified_lane_agility_time': types.FLOAT,\n",
    "    'three_quarter_sprint': types.FLOAT,\n",
    "    'bench_press': types.INTEGER,\n",
    "    'spot_fifteen_corner_left': types.DATE,\n",
    "    'spot_fifteen_break_left': types.DATE,\n",
    "    'spot_fifteen_top_key': types.DATE,\n",
    "    'spot_fifteen_break_right': types.DATE,\n",
    "    'spot_fifteen_corner_right': types.DATE,\n",
    "    'spot_college_corner_left': types.DATE,\n",
    "    'spot_college_break_left': types.DATE,\n",
    "    'spot_college_top_key': types.DATE,\n",
    "    'spot_college_break_right': types.DATE,\n",
    "    'spot_college_corner_right': types.DATE,\n",
    "    'spot_nba_corner_left': types.DATE,\n",
    "    'spot_nba_break_left': types.DATE,\n",
    "    'spot_nba_top_key': types.DATE,\n",
    "    'spot_nba_break_right': types.DATE,\n",
    "    'spot_nba_corner_right': types.DATE,\n",
    "    'off_drib_fifteen_break_left': types.DATE,\n",
    "    'off_drib_fifteen_top_key': types.DATE,\n",
    "    'off_drib_fifteen_break_right': types.DATE,\n",
    "    'off_drib_college_break_left': types.DATE,\n",
    "    'off_drib_college_top_key': types.DATE,\n",
    "    'off_drib_college_break_right': types.DATE,\n",
    "    'on_move_fifteen': types.DATE,\n",
    "    'on_move_college': types.DATE\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada BorradorDeEstadsticasCombinadas\n",
    "BorradorDeEstadsticasCombinadas.to_sql('BorradorDeEstadsticasCombinadas', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla BorradorDeEstadsticasCombinadas en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que InventarioID es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer InventarioID como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE BorradorDeEstadsticasCombinadas\n",
    "        ALTER COLUMN player_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla ComprasFinal2016\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE BorradorDeEstadsticasCombinadas\n",
    "        ADD CONSTRAINT PK_player_id PRIMARY KEY (player_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron duplicados en la columna 'person_id':\n",
      "      person_id  player_name  season  round_number  round_pick  overall_pick  \\\n",
      "39        76773          NaN    1947             0           0             0   \n",
      "51        79284          NaN    1947             0           0             0   \n",
      "103       77769          NaN    1948             0           0             0   \n",
      "126       76414          NaN    1948             0           0             0   \n",
      "131       76773          NaN    1948             0           0             0   \n",
      "...         ...          ...     ...           ...         ...           ...   \n",
      "5482      76195          NaN    1985             2           7            31   \n",
      "5493      83276          NaN    1985             2          18            42   \n",
      "5528        717          NaN    1985             4           7            77   \n",
      "5637        717          NaN    1986             1          24            24   \n",
      "5734      83276          NaN    1986             6           5           121   \n",
      "\n",
      "      draft_type     team_id  team_city  team_name  team_abbreviation  \\\n",
      "39           NaN  1610610024        NaN        NaN                NaN   \n",
      "51           NaN  1610610025        NaN        NaN                NaN   \n",
      "103          NaN  1610612747        NaN        NaN                NaN   \n",
      "126          NaN  1610610032        NaN        NaN                NaN   \n",
      "131          NaN  1610612752        NaN        NaN                NaN   \n",
      "...          ...         ...        ...        ...                ...   \n",
      "5482         NaN  1610612764        NaN        NaN                NaN   \n",
      "5493         NaN  1610612744        NaN        NaN                NaN   \n",
      "5528         NaN  1610612737        NaN        NaN                NaN   \n",
      "5637         NaN  1610612757        NaN        NaN                NaN   \n",
      "5734         NaN  1610612744        NaN        NaN                NaN   \n",
      "\n",
      "      organization  organization_type  player_profile_flag  \n",
      "39             NaN                NaN                    1  \n",
      "51             NaN                NaN                    0  \n",
      "103            NaN                NaN                    1  \n",
      "126            NaN                NaN                    1  \n",
      "131            NaN                NaN                    1  \n",
      "...            ...                ...                  ...  \n",
      "5482           NaN                NaN                    1  \n",
      "5493           NaN                NaN                    0  \n",
      "5528           NaN                NaN                    1  \n",
      "5637           NaN                NaN                    1  \n",
      "5734           NaN                NaN                    0  \n",
      "\n",
      "[246 rows x 14 columns]\n",
      "Duplicados eliminados.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\2034243432.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  BorradorDeHistoria['person_id'].fillna('0', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla BorradorDeHistoria en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "BorradorDeHistoria = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\BorradorDeHistoria_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'person_id'\n",
    "if 'person_id' in BorradorDeHistoria.columns:\n",
    "    duplicados = BorradorDeHistoria[BorradorDeHistoria.duplicated(subset=['person_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'person_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        BorradorDeHistoria = BorradorDeHistoria.drop_duplicates(subset=['person_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'person_id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'person_id' no tenga valores nulos y convertir a string\n",
    "BorradorDeHistoria['person_id'].fillna('0', inplace=True)\n",
    "BorradorDeHistoria['person_id'] = BorradorDeHistoria['person_id'].astype(str)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'person_id': types.INTEGER,\n",
    "    'player_name': types.VARCHAR(length=100),  # Se usará como PK\n",
    "    'season': types.INTEGER,\n",
    "    'round_number': types.INTEGER,\n",
    "    'round_pick': types.INTEGER,\n",
    "    'overall_pick': types.INTEGER,\n",
    "    'draft_type': types.VARCHAR(length=50),  # Puede ser texto corto\n",
    "    'team_id': types.INTEGER,\n",
    "    'team_city': types.VARCHAR(length=50),\n",
    "    'team_name': types.VARCHAR(length=50),\n",
    "    'team_abbreviation': types.VARCHAR(length=10),\n",
    "    'organization': types.VARCHAR(length=100),\n",
    "    'organization_type': types.VARCHAR(length=50),\n",
    "    'player_profile_flag': types.INTEGER\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada BorradorDeHistoria\n",
    "BorradorDeHistoria.to_sql('BorradorDeHistoria', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla BorradorDeHistoria en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que person_id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer person_id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE BorradorDeHistoria\n",
    "        ALTER COLUMN person_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla BorradorDeHistoria\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE BorradorDeHistoria\n",
    "        ADD CONSTRAINT PK_person_id PRIMARY KEY (person_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla DetallesDelEquipo en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\3774616185.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  DetallesDelEquipo['team_id'].fillna('0', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "DetallesDelEquipo = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\DetallesDelEquipo_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'team_id'\n",
    "if 'team_id' in DetallesDelEquipo.columns:\n",
    "    duplicados = DetallesDelEquipo[DetallesDelEquipo.duplicated(subset=['team_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'team_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        DetallesDelEquipo = DetallesDelEquipo.drop_duplicates(subset=['team_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'team_id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'team_id' no tenga valores nulos y convertir a string\n",
    "DetallesDelEquipo['team_id'].fillna('0', inplace=True)\n",
    "DetallesDelEquipo['team_id'] = DetallesDelEquipo['team_id'].astype(str)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'team_id': types.INTEGER,  # Se usará como PK\n",
    "    'abbreviation': types.VARCHAR(length=10),\n",
    "    'nickname': types.VARCHAR(length=50),\n",
    "    'yearfounded': types.FLOAT,\n",
    "    'city': types.VARCHAR(length=50),\n",
    "    'arena': types.VARCHAR(length=100),\n",
    "    'arenacapacity': types.FLOAT,\n",
    "    'owner': types.VARCHAR(length=100),\n",
    "    'generalmanager': types.VARCHAR(length=100),\n",
    "    'headcoach': types.VARCHAR(length=100),\n",
    "    'dleagueaffiliation': types.VARCHAR(length=50),\n",
    "    'facebook': types.VARCHAR(length=100),\n",
    "    'instagram': types.VARCHAR(length=100),\n",
    "    'twitter': types.VARCHAR(length=100)\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada DetallesDelEquipo\n",
    "DetallesDelEquipo.to_sql('DetallesDelEquipo', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla DetallesDelEquipo en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que team_id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer team_id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE DetallesDelEquipo\n",
    "        ALTER COLUMN team_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla DetallesDelEquipo\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE DetallesDelEquipo\n",
    "        ADD CONSTRAINT PK_team_id PRIMARY KEY (team_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\878328416.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  DetallesDelEquipo['team_id'].fillna('0', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla DetallesDelEquipo en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV completo\n",
    "DetallesDelEquipo = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\DetallesDelEquipo_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'team_id'\n",
    "if 'team_id' in DetallesDelEquipo.columns:\n",
    "    duplicados = DetallesDelEquipo[DetallesDelEquipo.duplicated(subset=['team_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'team_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        DetallesDelEquipo = DetallesDelEquipo.drop_duplicates(subset=['team_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'team_id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'team_id' no tenga valores nulos y convertir a string\n",
    "DetallesDelEquipo['team_id'].fillna('0', inplace=True)\n",
    "DetallesDelEquipo['team_id'] = DetallesDelEquipo['team_id'].astype(str)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'team_id': types.INTEGER,  # Se usará como PK\n",
    "    'abbreviation': types.VARCHAR(length=10),\n",
    "    'nickname': types.VARCHAR(length=50),\n",
    "    'yearfounded': types.FLOAT,\n",
    "    'city': types.VARCHAR(length=50),\n",
    "    'arena': types.VARCHAR(length=100),\n",
    "    'arenacapacity': types.FLOAT,\n",
    "    'owner': types.VARCHAR(length=100),\n",
    "    'generalmanager': types.VARCHAR(length=100),\n",
    "    'headcoach': types.VARCHAR(length=100),\n",
    "    'dleagueaffiliation': types.VARCHAR(length=50),\n",
    "    'facebook': types.VARCHAR(length=100),\n",
    "    'instagram': types.VARCHAR(length=100),\n",
    "    'twitter': types.VARCHAR(length=100)\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada DetallesDelEquipo\n",
    "DetallesDelEquipo.to_sql('DetallesDelEquipo', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla DetallesDelEquipo en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que team_id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer team_id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE DetallesDelEquipo\n",
    "        ALTER COLUMN team_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla DetallesDelEquipo\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE DetallesDelEquipo\n",
    "        ADD CONSTRAINT PK_team_id PRIMARY KEY (team_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron duplicados en la columna 'team_id':\n",
      "       team_id  city  nickname  year_founded  year_active_till\n",
      "0   1610612737   NaN       NaN          1968              2019\n",
      "1   1610612737   NaN       NaN          1955              1967\n",
      "2   1610612737   NaN       NaN          1951              1954\n",
      "3   1610612737   NaN       NaN          1949              1950\n",
      "7   1610612744   NaN       NaN          1971              2019\n",
      "8   1610612744   NaN       NaN          1962              1970\n",
      "9   1610612744   NaN       NaN          1946              1961\n",
      "10  1610612745   NaN       NaN          1971              2019\n",
      "11  1610612745   NaN       NaN          1967              1970\n",
      "12  1610612746   NaN       NaN          1984              2019\n",
      "13  1610612746   NaN       NaN          1978              1983\n",
      "14  1610612746   NaN       NaN          1970              1977\n",
      "15  1610612747   NaN       NaN          1960              2019\n",
      "16  1610612747   NaN       NaN          1948              1959\n",
      "20  1610612751   NaN       NaN          2012              2019\n",
      "21  1610612751   NaN       NaN          1977              2011\n",
      "22  1610612751   NaN       NaN          1976              1976\n",
      "24  1610612755   NaN       NaN          1963              2019\n",
      "25  1610612755   NaN       NaN          1949              1962\n",
      "28  1610612758   NaN       NaN          1985              2019\n",
      "29  1610612758   NaN       NaN          1975              1984\n",
      "30  1610612758   NaN       NaN          1972              1974\n",
      "31  1610612758   NaN       NaN          1957              1971\n",
      "32  1610612758   NaN       NaN          1948              1956\n",
      "34  1610612760   NaN       NaN          2008              2019\n",
      "35  1610612760   NaN       NaN          1967              2007\n",
      "37  1610612762   NaN       NaN          1979              2019\n",
      "38  1610612762   NaN       NaN          1974              1978\n",
      "39  1610612763   NaN       NaN          2001              2019\n",
      "40  1610612763   NaN       NaN          1995              2000\n",
      "41  1610612764   NaN       NaN          1997              2019\n",
      "42  1610612764   NaN       NaN          1974              1996\n",
      "43  1610612764   NaN       NaN          1973              1973\n",
      "44  1610612764   NaN       NaN          1963              1972\n",
      "45  1610612764   NaN       NaN          1962              1962\n",
      "46  1610612764   NaN       NaN          1961              1961\n",
      "47  1610612765   NaN       NaN          1957              2019\n",
      "48  1610612765   NaN       NaN          1948              1956\n",
      "49  1610612766   NaN       NaN          2014              2019\n",
      "50  1610612766   NaN       NaN          2004              2013\n",
      "51  1610612766   NaN       NaN          1988              2001\n",
      "Duplicados eliminados.\n",
      "Datos exportados exitosamente a la tabla HistoriaDelEquipo en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\773142995.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  HistoriaDelEquipo['team_id'].fillna('0', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV completo\n",
    "HistoriaDelEquipo = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\HistoriaDelEquipo_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'team_id'\n",
    "if 'team_id' in HistoriaDelEquipo.columns:\n",
    "    duplicados = HistoriaDelEquipo[HistoriaDelEquipo.duplicated(subset=['team_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'team_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        HistoriaDelEquipo = HistoriaDelEquipo.drop_duplicates(subset=['team_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'team_id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'team_id' no tenga valores nulos y convertir a string\n",
    "HistoriaDelEquipo['team_id'].fillna('0', inplace=True)\n",
    "HistoriaDelEquipo['team_id'] = HistoriaDelEquipo['team_id'].astype(str)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'team_id': types.INTEGER,  # Se usará como PK\n",
    "    'city': types.VARCHAR(length=50),\n",
    "    'nickname': types.VARCHAR(length=50),\n",
    "    'year_founded': types.FLOAT,\n",
    "    'year_active_till': types.FLOAT\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada HistoriaDelEquipo\n",
    "HistoriaDelEquipo.to_sql('HistoriaDelEquipo', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla HistoriaDelEquipo en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que team_id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer team_id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE HistoriaDelEquipo\n",
    "        ALTER COLUMN team_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla HistoriaDelEquipo\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE HistoriaDelEquipo\n",
    "        ADD CONSTRAINT PK_team_id PRIMARY KEY (team_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\2188510069.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  InformacionComunDelJugador['person_id'].fillna('0', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla InformacionComunDelJugador en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV completo\n",
    "InformacionComunDelJugador = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\InformacionComunDelJugador_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'person_id'\n",
    "if 'person_id' in InformacionComunDelJugador.columns:\n",
    "    duplicados = InformacionComunDelJugador[InformacionComunDelJugador.duplicated(subset=['person_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'person_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        InformacionComunDelJugador = InformacionComunDelJugador.drop_duplicates(subset=['person_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'person_id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'person_id' no tenga valores nulos y convertir a string\n",
    "InformacionComunDelJugador['person_id'].fillna('0', inplace=True)\n",
    "InformacionComunDelJugador['person_id'] = InformacionComunDelJugador['person_id'].astype(str)\n",
    "\n",
    "# Convertir las columnas con posibles valores numéricos a tipo float\n",
    "numerical_columns = ['height', 'weight', 'season_exp', 'draft_year', 'draft_round', 'draft_number', 'from_year', 'to_year']\n",
    "for col in numerical_columns:\n",
    "    InformacionComunDelJugador[col] = pd.to_numeric(InformacionComunDelJugador[col], errors='coerce')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'person_id': types.INTEGER,  # Se usará como PK\n",
    "    'first_name': types.VARCHAR(length=50),\n",
    "    'last_name': types.VARCHAR(length=50),\n",
    "    'display_first_last': types.VARCHAR(length=100),\n",
    "    'display_last_comma_first': types.VARCHAR(length=100),\n",
    "    'display_fi_last': types.VARCHAR(length=50),\n",
    "    'player_slug': types.VARCHAR(length=100),\n",
    "    'birthdate': types.DATE,\n",
    "    'school': types.VARCHAR(length=100),\n",
    "    'country': types.VARCHAR(length=50),\n",
    "    'last_affiliation': types.VARCHAR(length=100),\n",
    "    'height': types.FLOAT,\n",
    "    'weight': types.FLOAT,\n",
    "    'season_exp': types.FLOAT,\n",
    "    'jersey': types.VARCHAR(length=10),\n",
    "    'position': types.VARCHAR(length=20),\n",
    "    'rosterstatus': types.VARCHAR(length=20),\n",
    "    'games_played_current_season_flag': types.Boolean,  # Modificado a Boolean\n",
    "    'team_id': types.INTEGER,\n",
    "    'team_name': types.VARCHAR(length=50),\n",
    "    'team_abbreviation': types.VARCHAR(length=10),\n",
    "    'team_code': types.VARCHAR(length=10),\n",
    "    'team_city': types.VARCHAR(length=50),\n",
    "    'playercode': types.VARCHAR(length=100),\n",
    "    'from_year': types.FLOAT,\n",
    "    'to_year': types.FLOAT,\n",
    "    'dleague_flag': types.Boolean,  # Modificado a Boolean\n",
    "    'nba_flag': types.Boolean,  # Modificado a Boolean\n",
    "    'games_played_flag': types.Boolean,  # Modificado a Boolean\n",
    "    'draft_year': types.FLOAT,\n",
    "    'draft_round': types.FLOAT,\n",
    "    'draft_number': types.FLOAT,\n",
    "    'greatest_75_flag': types.Boolean  # Modificado a Boolean\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada InformacionComunDelJugador\n",
    "InformacionComunDelJugador.to_sql('InformacionComunDelJugador', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla InformacionComunDelJugador en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que person_id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer person_id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE InformacionComunDelJugador\n",
    "        ALTER COLUMN person_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla InformacionComunDelJugador\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE InformacionComunDelJugador\n",
    "        ADD CONSTRAINT PK_person_id PRIMARY KEY (person_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron duplicados en la columna 'game_id':\n",
      "        game_id   game_date  attendance            game_time\n",
      "1613   35000001  1951-03-02     16205.0                  NaN\n",
      "1614   35000001  1951-03-02     16205.0                  NaN\n",
      "1921   35100001  1952-02-11     16205.0                  NaN\n",
      "1922   35100001  1952-02-11     16205.0                  NaN\n",
      "2244   35200001  1953-01-13     16205.0                  NaN\n",
      "...         ...         ...         ...                  ...\n",
      "50922  31600001  2017-02-19     15701.0  2024-11-16 02:18:00\n",
      "53393  31800001  2019-02-17     16205.0  2024-11-16 02:19:00\n",
      "53394  31800001  2019-02-17     16205.0  2024-11-16 02:19:00\n",
      "58051  32200001  2023-02-19     17886.0  2024-11-16 00:00:00\n",
      "58052  32200001  2023-02-19     17886.0  2024-11-16 00:00:00\n",
      "\n",
      "[80 rows x 4 columns]\n",
      "Duplicados eliminados.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\2455664783.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  InformacionDelJuego['game_id'].fillna('0', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla InformacionDelJuego en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV completo\n",
    "InformacionDelJuego = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\InformacionDelJuego_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'game_id'\n",
    "if 'game_id' in InformacionDelJuego.columns:\n",
    "    duplicados = InformacionDelJuego[InformacionDelJuego.duplicated(subset=['game_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'game_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        InformacionDelJuego = InformacionDelJuego.drop_duplicates(subset=['game_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'game_id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'game_id' no tenga valores nulos y convertir a string\n",
    "InformacionDelJuego['game_id'].fillna('0', inplace=True)\n",
    "InformacionDelJuego['game_id'] = InformacionDelJuego['game_id'].astype(str)\n",
    "\n",
    "# Convertir la columna 'game_date' a formato de fecha\n",
    "InformacionDelJuego['game_date'] = pd.to_datetime(InformacionDelJuego['game_date'], errors='coerce')\n",
    "\n",
    "# Convertir las columnas con posibles valores numéricos a tipo float\n",
    "InformacionDelJuego['attendance'] = pd.to_numeric(InformacionDelJuego['attendance'], errors='coerce')\n",
    "\n",
    "# Asegurarse que 'game_time' sea un string (para cualquier formato de hora)\n",
    "InformacionDelJuego['game_time'] = InformacionDelJuego['game_time'].astype(str)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'game_id': types.INTEGER,  # Se usará como PK\n",
    "    'game_date': types.DATE,\n",
    "    'attendance': types.FLOAT,\n",
    "    'game_time': types.VARCHAR(length=50)\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada InformacionDelJuego\n",
    "InformacionDelJuego.to_sql('InformacionDelJuego', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla InformacionDelJuego en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que game_id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer game_id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE InformacionDelJuego\n",
    "        ALTER COLUMN game_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla InformacionDelJuego\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE InformacionDelJuego\n",
    "        ADD CONSTRAINT PK_game_id PRIMARY KEY (game_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron duplicados en la columna 'game_id':\n",
      "       season_id  team_id_home  team_abbreviation_home  team_name_home  \\\n",
      "1918       31950    1610616833                     NaN             NaN   \n",
      "1919       31950    1610616833                     NaN             NaN   \n",
      "2275       31951    1610616833                     NaN             NaN   \n",
      "2276       31951    1610616833                     NaN             NaN   \n",
      "2651       31952    1610616833                     NaN             NaN   \n",
      "...          ...           ...                     ...             ...   \n",
      "60568      32018    1610616833                     NaN             NaN   \n",
      "62926      32020    1610616833                     NaN             NaN   \n",
      "62927      32020    1610616833                     NaN             NaN   \n",
      "65696      32022    1610616834                     NaN             NaN   \n",
      "65697      32022    1610616834                     NaN             NaN   \n",
      "\n",
      "        game_id   game_date  matchup_home  wl_home  min  fgm_home  ...  \\\n",
      "1918   35000001  1951-03-02           NaN      NaN  240      43.0  ...   \n",
      "1919   35000001  1951-03-02           NaN      NaN  240      43.0  ...   \n",
      "2275   35100001  1952-02-11           NaN      NaN  240      39.0  ...   \n",
      "2276   35100001  1952-02-11           NaN      NaN  240      39.0  ...   \n",
      "2651   35200001  1953-01-13           NaN      NaN  240      25.0  ...   \n",
      "...         ...         ...           ...      ...  ...       ...  ...   \n",
      "60568  31800001  2019-02-17           NaN      NaN  240      66.0  ...   \n",
      "62926  32000001  2021-03-07           NaN      NaN  240      60.0  ...   \n",
      "62927  32000001  2021-03-07           NaN      NaN  240      60.0  ...   \n",
      "65696  32200001  2023-02-19           NaN      NaN  221      79.0  ...   \n",
      "65697  32200001  2023-02-19           NaN      NaN  221      79.0  ...   \n",
      "\n",
      "       reb_away ast_away  stl_away  blk_away  tov_away  pf_away  pts_away  \\\n",
      "1918       60.0     27.0       0.0       0.0       0.0     25.0      94.0   \n",
      "1919       60.0     27.0       0.0       0.0       0.0     25.0      94.0   \n",
      "2275       59.0     27.0       0.0       0.0       0.0     28.0      91.0   \n",
      "2276       59.0     27.0       0.0       0.0       0.0     28.0      91.0   \n",
      "2651       59.0     26.0       0.0       0.0       0.0     23.0      79.0   \n",
      "...         ...      ...       ...       ...       ...      ...       ...   \n",
      "60568      64.0     42.0       9.0       6.0       9.0      9.0     178.0   \n",
      "62926      48.0     46.0       9.0       3.0      18.0      8.0     170.0   \n",
      "62927      48.0     46.0       9.0       3.0      18.0      8.0     170.0   \n",
      "65696      46.0     43.0       8.0       1.0      12.0      2.0     184.0   \n",
      "65697      46.0     43.0       8.0       1.0      12.0      2.0     184.0   \n",
      "\n",
      "       plus_minus_away  video_available_away  season_type  \n",
      "1918               -17                     0          NaN  \n",
      "1919               -17                     0          NaN  \n",
      "2275               -17                     0          NaN  \n",
      "2276               -17                     0          NaN  \n",
      "2651                 4                     0          NaN  \n",
      "...                ...                   ...          ...  \n",
      "60568               14                     0          NaN  \n",
      "62926               20                     1          NaN  \n",
      "62927               20                     1          NaN  \n",
      "65696                9                     1          NaN  \n",
      "65697                9                     1          NaN  \n",
      "\n",
      "[112 rows x 55 columns]\n",
      "Duplicados eliminados.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\4233136460.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  Juego['game_id'].fillna('0', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla Juego en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV completo\n",
    "Juego = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\Juego_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'game_id'\n",
    "if 'game_id' in Juego.columns:\n",
    "    duplicados = Juego[Juego.duplicated(subset=['game_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'game_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        Juego = Juego.drop_duplicates(subset=['game_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'game_id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'game_id' no tenga valores nulos y convertir a string\n",
    "Juego['game_id'].fillna('0', inplace=True)\n",
    "Juego['game_id'] = Juego['game_id'].astype(str)\n",
    "\n",
    "# Convertir la columna 'game_date' a formato de fecha\n",
    "Juego['game_date'] = pd.to_datetime(Juego['game_date'], errors='coerce')\n",
    "\n",
    "# Convertir las columnas con posibles valores numéricos a tipo float\n",
    "numerical_columns = [\n",
    "    'fgm_home', 'fga_home', 'fg_pct_home', 'fg3m_home', 'fg3a_home', 'fg3_pct_home', 'ftm_home', 'fta_home',\n",
    "    'ft_pct_home', 'oreb_home', 'dreb_home', 'reb_home', 'ast_home', 'stl_home', 'blk_home', 'tov_home', 'pf_home', \n",
    "    'pts_home', 'plus_minus_home', 'fgm_away', 'fga_away', 'fg_pct_away', 'fg3m_away', 'fg3a_away', 'fg3_pct_away', \n",
    "    'ftm_away', 'fta_away', 'ft_pct_away', 'oreb_away', 'dreb_away', 'reb_away', 'ast_away', 'stl_away', 'blk_away', \n",
    "    'tov_away', 'pf_away', 'pts_away', 'plus_minus_away', 'season_id'\n",
    "]\n",
    "\n",
    "# Convertir a float\n",
    "Juego[numerical_columns] = Juego[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convertir las demás columnas relevantes a tipo string\n",
    "categorical_columns = [\n",
    "    'team_id_home', 'team_abbreviation_home', 'team_name_home', 'matchup_home', 'wl_home', 'video_available_home',\n",
    "    'team_id_away', 'team_abbreviation_away', 'team_name_away', 'matchup_away', 'wl_away', 'video_available_away', \n",
    "    'season_type'\n",
    "]\n",
    "Juego[categorical_columns] = Juego[categorical_columns].astype(str)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'season_id': types.FLOAT,\n",
    "    'team_id_home': types.INTEGER,\n",
    "    'team_abbreviation_home': types.VARCHAR(length=10),\n",
    "    'team_name_home': types.VARCHAR(length=50),\n",
    "    'game_id': types.INTEGER,  # Se usará como PK\n",
    "    'game_date': types.DATE,\n",
    "    'matchup_home': types.VARCHAR(length=100),\n",
    "    'wl_home': types.VARCHAR(length=10),\n",
    "    'min': types.FLOAT,\n",
    "    'fgm_home': types.FLOAT,\n",
    "    'fga_home': types.FLOAT,\n",
    "    'fg_pct_home': types.FLOAT,\n",
    "    'fg3m_home': types.FLOAT,\n",
    "    'fg3a_home': types.FLOAT,\n",
    "    'fg3_pct_home': types.FLOAT,\n",
    "    'ftm_home': types.FLOAT,\n",
    "    'fta_home': types.FLOAT,\n",
    "    'ft_pct_home': types.FLOAT,\n",
    "    'oreb_home': types.FLOAT,\n",
    "    'dreb_home': types.FLOAT,\n",
    "    'reb_home': types.FLOAT,\n",
    "    'ast_home': types.FLOAT,\n",
    "    'stl_home': types.FLOAT,\n",
    "    'blk_home': types.FLOAT,\n",
    "    'tov_home': types.FLOAT,\n",
    "    'pf_home': types.FLOAT,\n",
    "    'pts_home': types.FLOAT,\n",
    "    'plus_minus_home': types.FLOAT,\n",
    "    'video_available_home': types.VARCHAR(length=10),\n",
    "    'team_id_away': types.INTEGER,\n",
    "    'team_abbreviation_away': types.VARCHAR(length=10),\n",
    "    'team_name_away': types.VARCHAR(length=50),\n",
    "    'matchup_away': types.VARCHAR(length=100),\n",
    "    'wl_away': types.VARCHAR(length=10),\n",
    "    'fgm_away': types.FLOAT,\n",
    "    'fga_away': types.FLOAT,\n",
    "    'fg_pct_away': types.FLOAT,\n",
    "    'fg3m_away': types.FLOAT,\n",
    "    'fg3a_away': types.FLOAT,\n",
    "    'fg3_pct_away': types.FLOAT,\n",
    "    'ftm_away': types.FLOAT,\n",
    "    'fta_away': types.FLOAT,\n",
    "    'ft_pct_away': types.FLOAT,\n",
    "    'oreb_away': types.FLOAT,\n",
    "    'dreb_away': types.FLOAT,\n",
    "    'reb_away': types.FLOAT,\n",
    "    'ast_away': types.FLOAT,\n",
    "    'stl_away': types.FLOAT,\n",
    "    'blk_away': types.FLOAT,\n",
    "    'tov_away': types.FLOAT,\n",
    "    'pf_away': types.FLOAT,\n",
    "    'pts_away': types.FLOAT,\n",
    "    'plus_minus_away': types.FLOAT,\n",
    "    'video_available_away': types.VARCHAR(length=10),\n",
    "    'season_type': types.VARCHAR(length=10)\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada Juego\n",
    "Juego.to_sql('Juego', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla Juego en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que game_id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer game_id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE Juego\n",
    "        ALTER COLUMN game_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla Juego\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE Juego\n",
    "        ADD CONSTRAINT PK_game_id PRIMARY KEY (game_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron duplicados en la columna 'game_id':\n",
      "       season_id  team_id_home  team_abbreviation_home  team_name_home  \\\n",
      "1918       31950    1610616833                     NaN             NaN   \n",
      "1919       31950    1610616833                     NaN             NaN   \n",
      "2275       31951    1610616833                     NaN             NaN   \n",
      "2276       31951    1610616833                     NaN             NaN   \n",
      "2651       31952    1610616833                     NaN             NaN   \n",
      "...          ...           ...                     ...             ...   \n",
      "60568      32018    1610616833                     NaN             NaN   \n",
      "62926      32020    1610616833                     NaN             NaN   \n",
      "62927      32020    1610616833                     NaN             NaN   \n",
      "65696      32022    1610616834                     NaN             NaN   \n",
      "65697      32022    1610616834                     NaN             NaN   \n",
      "\n",
      "        game_id   game_date  matchup_home  wl_home  min  fgm_home  ...  \\\n",
      "1918   35000001  1951-03-02           NaN      NaN  240      43.0  ...   \n",
      "1919   35000001  1951-03-02           NaN      NaN  240      43.0  ...   \n",
      "2275   35100001  1952-02-11           NaN      NaN  240      39.0  ...   \n",
      "2276   35100001  1952-02-11           NaN      NaN  240      39.0  ...   \n",
      "2651   35200001  1953-01-13           NaN      NaN  240      25.0  ...   \n",
      "...         ...         ...           ...      ...  ...       ...  ...   \n",
      "60568  31800001  2019-02-17           NaN      NaN  240      66.0  ...   \n",
      "62926  32000001  2021-03-07           NaN      NaN  240      60.0  ...   \n",
      "62927  32000001  2021-03-07           NaN      NaN  240      60.0  ...   \n",
      "65696  32200001  2023-02-19           NaN      NaN  221      79.0  ...   \n",
      "65697  32200001  2023-02-19           NaN      NaN  221      79.0  ...   \n",
      "\n",
      "       reb_away ast_away  stl_away  blk_away  tov_away  pf_away  pts_away  \\\n",
      "1918       60.0     27.0       0.0       0.0       0.0     25.0      94.0   \n",
      "1919       60.0     27.0       0.0       0.0       0.0     25.0      94.0   \n",
      "2275       59.0     27.0       0.0       0.0       0.0     28.0      91.0   \n",
      "2276       59.0     27.0       0.0       0.0       0.0     28.0      91.0   \n",
      "2651       59.0     26.0       0.0       0.0       0.0     23.0      79.0   \n",
      "...         ...      ...       ...       ...       ...      ...       ...   \n",
      "60568      64.0     42.0       9.0       6.0       9.0      9.0     178.0   \n",
      "62926      48.0     46.0       9.0       3.0      18.0      8.0     170.0   \n",
      "62927      48.0     46.0       9.0       3.0      18.0      8.0     170.0   \n",
      "65696      46.0     43.0       8.0       1.0      12.0      2.0     184.0   \n",
      "65697      46.0     43.0       8.0       1.0      12.0      2.0     184.0   \n",
      "\n",
      "       plus_minus_away  video_available_away  season_type  \n",
      "1918               -17                     0          NaN  \n",
      "1919               -17                     0          NaN  \n",
      "2275               -17                     0          NaN  \n",
      "2276               -17                     0          NaN  \n",
      "2651                 4                     0          NaN  \n",
      "...                ...                   ...          ...  \n",
      "60568               14                     0          NaN  \n",
      "62926               20                     1          NaN  \n",
      "62927               20                     1          NaN  \n",
      "65696                9                     1          NaN  \n",
      "65697                9                     1          NaN  \n",
      "\n",
      "[112 rows x 55 columns]\n",
      "Duplicados eliminados.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\4233136460.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  Juego['game_id'].fillna('0', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla Juego en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV completo\n",
    "Juego = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\Juego_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'game_id'\n",
    "if 'game_id' in Juego.columns:\n",
    "    duplicados = Juego[Juego.duplicated(subset=['game_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'game_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        Juego = Juego.drop_duplicates(subset=['game_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'game_id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'game_id' no tenga valores nulos y convertir a string\n",
    "Juego['game_id'].fillna('0', inplace=True)\n",
    "Juego['game_id'] = Juego['game_id'].astype(str)\n",
    "\n",
    "# Convertir la columna 'game_date' a formato de fecha\n",
    "Juego['game_date'] = pd.to_datetime(Juego['game_date'], errors='coerce')\n",
    "\n",
    "# Convertir las columnas con posibles valores numéricos a tipo float\n",
    "numerical_columns = [\n",
    "    'fgm_home', 'fga_home', 'fg_pct_home', 'fg3m_home', 'fg3a_home', 'fg3_pct_home', 'ftm_home', 'fta_home',\n",
    "    'ft_pct_home', 'oreb_home', 'dreb_home', 'reb_home', 'ast_home', 'stl_home', 'blk_home', 'tov_home', 'pf_home', \n",
    "    'pts_home', 'plus_minus_home', 'fgm_away', 'fga_away', 'fg_pct_away', 'fg3m_away', 'fg3a_away', 'fg3_pct_away', \n",
    "    'ftm_away', 'fta_away', 'ft_pct_away', 'oreb_away', 'dreb_away', 'reb_away', 'ast_away', 'stl_away', 'blk_away', \n",
    "    'tov_away', 'pf_away', 'pts_away', 'plus_minus_away', 'season_id'\n",
    "]\n",
    "\n",
    "# Convertir a float\n",
    "Juego[numerical_columns] = Juego[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convertir las demás columnas relevantes a tipo string\n",
    "categorical_columns = [\n",
    "    'team_id_home', 'team_abbreviation_home', 'team_name_home', 'matchup_home', 'wl_home', 'video_available_home',\n",
    "    'team_id_away', 'team_abbreviation_away', 'team_name_away', 'matchup_away', 'wl_away', 'video_available_away', \n",
    "    'season_type'\n",
    "]\n",
    "Juego[categorical_columns] = Juego[categorical_columns].astype(str)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'season_id': types.FLOAT,\n",
    "    'team_id_home': types.INTEGER,\n",
    "    'team_abbreviation_home': types.VARCHAR(length=10),\n",
    "    'team_name_home': types.VARCHAR(length=50),\n",
    "    'game_id': types.INTEGER,  # Se usará como PK\n",
    "    'game_date': types.DATE,\n",
    "    'matchup_home': types.VARCHAR(length=100),\n",
    "    'wl_home': types.VARCHAR(length=10),\n",
    "    'min': types.FLOAT,\n",
    "    'fgm_home': types.FLOAT,\n",
    "    'fga_home': types.FLOAT,\n",
    "    'fg_pct_home': types.FLOAT,\n",
    "    'fg3m_home': types.FLOAT,\n",
    "    'fg3a_home': types.FLOAT,\n",
    "    'fg3_pct_home': types.FLOAT,\n",
    "    'ftm_home': types.FLOAT,\n",
    "    'fta_home': types.FLOAT,\n",
    "    'ft_pct_home': types.FLOAT,\n",
    "    'oreb_home': types.FLOAT,\n",
    "    'dreb_home': types.FLOAT,\n",
    "    'reb_home': types.FLOAT,\n",
    "    'ast_home': types.FLOAT,\n",
    "    'stl_home': types.FLOAT,\n",
    "    'blk_home': types.FLOAT,\n",
    "    'tov_home': types.FLOAT,\n",
    "    'pf_home': types.FLOAT,\n",
    "    'pts_home': types.FLOAT,\n",
    "    'plus_minus_home': types.FLOAT,\n",
    "    'video_available_home': types.VARCHAR(length=10),\n",
    "    'team_id_away': types.INTEGER,\n",
    "    'team_abbreviation_away': types.VARCHAR(length=10),\n",
    "    'team_name_away': types.VARCHAR(length=50),\n",
    "    'matchup_away': types.VARCHAR(length=100),\n",
    "    'wl_away': types.VARCHAR(length=10),\n",
    "    'fgm_away': types.FLOAT,\n",
    "    'fga_away': types.FLOAT,\n",
    "    'fg_pct_away': types.FLOAT,\n",
    "    'fg3m_away': types.FLOAT,\n",
    "    'fg3a_away': types.FLOAT,\n",
    "    'fg3_pct_away': types.FLOAT,\n",
    "    'ftm_away': types.FLOAT,\n",
    "    'fta_away': types.FLOAT,\n",
    "    'ft_pct_away': types.FLOAT,\n",
    "    'oreb_away': types.FLOAT,\n",
    "    'dreb_away': types.FLOAT,\n",
    "    'reb_away': types.FLOAT,\n",
    "    'ast_away': types.FLOAT,\n",
    "    'stl_away': types.FLOAT,\n",
    "    'blk_away': types.FLOAT,\n",
    "    'tov_away': types.FLOAT,\n",
    "    'pf_away': types.FLOAT,\n",
    "    'pts_away': types.FLOAT,\n",
    "    'plus_minus_away': types.FLOAT,\n",
    "    'video_available_away': types.VARCHAR(length=10),\n",
    "    'season_type': types.VARCHAR(length=10)\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada Juego\n",
    "Juego.to_sql('Juego', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla Juego en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que game_id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer game_id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE Juego\n",
    "        ALTER COLUMN game_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla Juego\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE Juego\n",
    "        ADD CONSTRAINT PK_game_id PRIMARY KEY (game_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\689647566.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  Jugador['id'].fillna('0', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla Jugador en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV completo\n",
    "Jugador = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\Jugador_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'id'\n",
    "if 'id' in Jugador.columns:\n",
    "    duplicados = Jugador[Jugador.duplicated(subset=['id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        Jugador = Jugador.drop_duplicates(subset=['id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'id' no tenga valores nulos y convertir a string\n",
    "Jugador['id'].fillna('0', inplace=True)\n",
    "Jugador['id'] = Jugador['id'].astype(str)\n",
    "\n",
    "# Convertir las columnas relevantes a tipo string\n",
    "Jugador['full_name'] = Jugador['full_name'].astype(str)\n",
    "Jugador['first_name'] = Jugador['first_name'].astype(str)\n",
    "Jugador['last_name'] = Jugador['last_name'].astype(str)\n",
    "\n",
    "# Asegurarse de que 'is_active' sea un tipo numérico (0 o 1)\n",
    "Jugador['is_active'] = pd.to_numeric(Jugador['is_active'], errors='coerce')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'id': types.INTEGER,  # Se usará como PK\n",
    "    'full_name': types.VARCHAR(length=100),\n",
    "    'first_name': types.VARCHAR(length=50),\n",
    "    'last_name': types.VARCHAR(length=50),\n",
    "    'is_active': types.INTEGER\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada Jugador\n",
    "Jugador.to_sql('Jugador', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla Jugador en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE Jugador\n",
    "        ALTER COLUMN id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla Jugador\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE Jugador\n",
    "        ADD CONSTRAINT PK_id PRIMARY KEY (id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron duplicados en la columna 'game_id':\n",
      "         game_id  player_id  first_name  last_name  jersey_num     team_id  \\\n",
      "0       29600034        184         NaN        NaN        14.0  1610612739   \n",
      "1       29600034        781         NaN        NaN        41.0  1610612759   \n",
      "8       29600335        420         NaN        NaN        55.0  1610612751   \n",
      "9       29600335        762         NaN        NaN        45.0  1610612751   \n",
      "17      29600593        168         NaN        NaN        24.0  1610612739   \n",
      "...          ...        ...         ...        ...         ...         ...   \n",
      "110186  32200001    1629627         NaN        NaN         1.0  1610616834   \n",
      "110187  32200001     201939         NaN        NaN        30.0  1610616834   \n",
      "110188  32200001     201142         NaN        NaN        35.0  1610616833   \n",
      "110189  32200001    1629627         NaN        NaN         1.0  1610616834   \n",
      "110190  32200001     201939         NaN        NaN        30.0  1610616834   \n",
      "\n",
      "        team_city  team_name  team_abbreviation  \n",
      "0             NaN        NaN                NaN  \n",
      "1             NaN        NaN                NaN  \n",
      "8             NaN        NaN                NaN  \n",
      "9             NaN        NaN                NaN  \n",
      "17            NaN        NaN                NaN  \n",
      "...           ...        ...                ...  \n",
      "110186        NaN        NaN                NaN  \n",
      "110187        NaN        NaN                NaN  \n",
      "110188        NaN        NaN                NaN  \n",
      "110189        NaN        NaN                NaN  \n",
      "110190        NaN        NaN                NaN  \n",
      "\n",
      "[109749 rows x 9 columns]\n",
      "Duplicados eliminados.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\3666948597.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  JugadoresInactivos['game_id'].fillna('0', inplace=True)\n",
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\3666948597.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  JugadoresInactivos['player_id'].fillna('0', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla JugadoresInactivos en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV completo\n",
    "JugadoresInactivos = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\JugadoresInactivos_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'game_id'\n",
    "if 'game_id' in JugadoresInactivos.columns:\n",
    "    duplicados = JugadoresInactivos[JugadoresInactivos.duplicated(subset=['game_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'game_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        JugadoresInactivos = JugadoresInactivos.drop_duplicates(subset=['game_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'game_id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'game_id' no tenga valores nulos y convertir a string\n",
    "JugadoresInactivos['game_id'].fillna('0', inplace=True)\n",
    "JugadoresInactivos['game_id'] = JugadoresInactivos['game_id'].astype(str)\n",
    "\n",
    "# Asegurar que la columna 'player_id' no tenga valores nulos y convertir a string\n",
    "JugadoresInactivos['player_id'].fillna('0', inplace=True)\n",
    "JugadoresInactivos['player_id'] = JugadoresInactivos['player_id'].astype(str)\n",
    "\n",
    "# Convertir las columnas relevantes a tipo string\n",
    "JugadoresInactivos['first_name'] = JugadoresInactivos['first_name'].astype(str)\n",
    "JugadoresInactivos['last_name'] = JugadoresInactivos['last_name'].astype(str)\n",
    "JugadoresInactivos['team_city'] = JugadoresInactivos['team_city'].astype(str)\n",
    "JugadoresInactivos['team_name'] = JugadoresInactivos['team_name'].astype(str)\n",
    "JugadoresInactivos['team_abbreviation'] = JugadoresInactivos['team_abbreviation'].astype(str)\n",
    "\n",
    "# Convertir las columnas numéricas a tipo float o int\n",
    "JugadoresInactivos['jersey_num'] = pd.to_numeric(JugadoresInactivos['jersey_num'], errors='coerce')\n",
    "JugadoresInactivos['team_id'] = pd.to_numeric(JugadoresInactivos['team_id'], errors='coerce')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'game_id': types.INTEGER,  # Se usará como PK\n",
    "    'player_id': types.INTEGER,\n",
    "    'first_name': types.VARCHAR(length=50),\n",
    "    'last_name': types.VARCHAR(length=50),\n",
    "    'jersey_num': types.FLOAT,\n",
    "    'team_id': types.INTEGER,\n",
    "    'team_city': types.VARCHAR(length=50),\n",
    "    'team_name': types.VARCHAR(length=50),\n",
    "    'team_abbreviation': types.VARCHAR(length=10)\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada JugadoresInactivos\n",
    "JugadoresInactivos.to_sql('JugadoresInactivos', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla JugadoresInactivos en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que game_id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer game_id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE JugadoresInactivos\n",
    "        ALTER COLUMN game_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla JugadoresInactivos\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE JugadoresInactivos\n",
    "        ADD CONSTRAINT PK_game_id PRIMARY KEY (game_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron duplicados en la columna 'game_id':\n",
      "        game_id  official_id  first_name  last_name  jersey_num\n",
      "0      29600059         1140         NaN        NaN         9.0\n",
      "1      29600059         1165         NaN        NaN         8.0\n",
      "2      29600059         1153         NaN        NaN        17.0\n",
      "3      29600114         1147         NaN        NaN        24.0\n",
      "4      29600114         1142         NaN        NaN        27.0\n",
      "...         ...          ...         ...        ...         ...\n",
      "70966  32200001       200834         NaN        NaN        29.0\n",
      "70967  32200001         1193         NaN        NaN        38.0\n",
      "70968  32200001       101284         NaN        NaN        10.0\n",
      "70969  32200001       200834         NaN        NaN        29.0\n",
      "70970  32200001         1193         NaN        NaN        38.0\n",
      "\n",
      "[70971 rows x 5 columns]\n",
      "Duplicados eliminados.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\751348073.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  Oficiales['game_id'].fillna('0', inplace=True)\n",
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\751348073.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  Oficiales['official_id'].fillna('0', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla Oficiales en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV completo\n",
    "Oficiales = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\Oficiales_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'game_id'\n",
    "if 'game_id' in Oficiales.columns:\n",
    "    duplicados = Oficiales[Oficiales.duplicated(subset=['game_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'game_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        Oficiales = Oficiales.drop_duplicates(subset=['game_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'game_id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'game_id' no tenga valores nulos y convertir a string\n",
    "Oficiales['game_id'].fillna('0', inplace=True)\n",
    "Oficiales['game_id'] = Oficiales['game_id'].astype(str)\n",
    "\n",
    "# Asegurar que la columna 'official_id' no tenga valores nulos y convertir a string\n",
    "Oficiales['official_id'].fillna('0', inplace=True)\n",
    "Oficiales['official_id'] = Oficiales['official_id'].astype(str)\n",
    "\n",
    "# Convertir las columnas relevantes a tipo string\n",
    "Oficiales['first_name'] = Oficiales['first_name'].astype(str)\n",
    "Oficiales['last_name'] = Oficiales['last_name'].astype(str)\n",
    "\n",
    "# Convertir la columna jersey_num a tipo float\n",
    "Oficiales['jersey_num'] = pd.to_numeric(Oficiales['jersey_num'], errors='coerce')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'game_id': types.INTEGER,  # Se usará como PK\n",
    "    'official_id': types.INTEGER,\n",
    "    'first_name': types.VARCHAR(length=50),\n",
    "    'last_name': types.VARCHAR(length=50),\n",
    "    'jersey_num': types.FLOAT\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada Oficiales\n",
    "Oficiales.to_sql('Oficiales', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla Oficiales en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que game_id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer game_id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE Oficiales\n",
    "        ALTER COLUMN game_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla Oficiales\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE Oficiales\n",
    "        ADD CONSTRAINT PK_game_id PRIMARY KEY (game_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron duplicados en la columna 'game_id':\n",
      "        game_id  league_id  team_id_home  team_abbreviation_home  \\\n",
      "1022   39600001          0    1610616834                     NaN   \n",
      "1023   39600001          0    1610616834                     NaN   \n",
      "3745   39900001          0    1610616833                     NaN   \n",
      "3746   39900001          0    1610616833                     NaN   \n",
      "6860   30200001          0    1610616834                     NaN   \n",
      "6861   30200001          0    1610616834                     NaN   \n",
      "14417  30900001          0    1610616833                     NaN   \n",
      "14418  30900001          0    1610616833                     NaN   \n",
      "15652  31000001          0    1610616834                     NaN   \n",
      "15653  31000001          0    1610616834                     NaN   \n",
      "16746  31200001          0    1610616833                     NaN   \n",
      "16747  31200001          0    1610616833                     NaN   \n",
      "19193  31400001          0    1610616834                     NaN   \n",
      "19194  31400001          0    1610616834                     NaN   \n",
      "21610  31600001          0    1610616834                     NaN   \n",
      "21611  31600001          0    1610616834                     NaN   \n",
      "23900  31800001          0    1610616833                     NaN   \n",
      "23901  31800001          0    1610616833                     NaN   \n",
      "28269  32200001          0    1610616834                     NaN   \n",
      "28270  32200001          0    1610616834                     NaN   \n",
      "\n",
      "       team_city_home  pts_paint_home  pts_2nd_chance_home  pts_fb_home  \\\n",
      "1022              NaN              74                   10           26   \n",
      "1023              NaN              74                   10           26   \n",
      "3745              NaN              54                   29           21   \n",
      "3746              NaN              54                   29           21   \n",
      "6860              NaN              88                   21           32   \n",
      "6861              NaN              88                   21           32   \n",
      "14417             NaN              88                   11           56   \n",
      "14418             NaN              88                   11           56   \n",
      "15652             NaN              80                   35           43   \n",
      "15653             NaN              80                   35           43   \n",
      "16746             NaN              66                   15           21   \n",
      "16747             NaN              66                   15           21   \n",
      "19193             NaN              68                   22           59   \n",
      "19194             NaN              68                   22           59   \n",
      "21610             NaN             120                   23          106   \n",
      "21611             NaN             120                   23          106   \n",
      "23900             NaN              78                   26           37   \n",
      "23901             NaN              78                   26           37   \n",
      "28269             NaN             118                   15           27   \n",
      "28270             NaN             118                   15           27   \n",
      "\n",
      "       largest_lead_home  lead_changes  ...  team_abbreviation_away  \\\n",
      "1022                  23             4  ...                     NaN   \n",
      "1023                  23             4  ...                     NaN   \n",
      "3745                   2             2  ...                     NaN   \n",
      "3746                   2             2  ...                     NaN   \n",
      "6860                  11            26  ...                     NaN   \n",
      "6861                  11            26  ...                     NaN   \n",
      "14417                 16            13  ...                     NaN   \n",
      "14418                 16            13  ...                     NaN   \n",
      "15652                 17             1  ...                     NaN   \n",
      "15653                 17             1  ...                     NaN   \n",
      "16746                  2            22  ...                     NaN   \n",
      "16747                  2            22  ...                     NaN   \n",
      "19193                 20            17  ...                     NaN   \n",
      "19194                 20            17  ...                     NaN   \n",
      "21610                 15            16  ...                     NaN   \n",
      "21611                 15            16  ...                     NaN   \n",
      "23900                 20             9  ...                     NaN   \n",
      "23901                 20             9  ...                     NaN   \n",
      "28269                  4            24  ...                     NaN   \n",
      "28270                  4            24  ...                     NaN   \n",
      "\n",
      "       team_city_away  pts_paint_away  pts_2nd_chance_away  pts_fb_away  \\\n",
      "1022              NaN              80                   38           24   \n",
      "1023              NaN              80                   38           24   \n",
      "3745              NaN              86                   34           26   \n",
      "3746              NaN              86                   34           26   \n",
      "6860              NaN              64                   15           31   \n",
      "6861              NaN              64                   15           31   \n",
      "14417             NaN              74                   21           24   \n",
      "14418             NaN              74                   21           24   \n",
      "15652             NaN              86                   22           53   \n",
      "15653             NaN              86                   22           53   \n",
      "16746             NaN              88                   13           38   \n",
      "16747             NaN              88                   13           38   \n",
      "19193             NaN              82                   25           61   \n",
      "19194             NaN              82                   25           61   \n",
      "21610             NaN             106                   14          107   \n",
      "21611             NaN             106                   14          107   \n",
      "23900             NaN              62                   19           33   \n",
      "23901             NaN              62                   19           33   \n",
      "28269             NaN              88                   14           33   \n",
      "28270             NaN              88                   14           33   \n",
      "\n",
      "       largest_lead_away  team_turnovers_away  total_turnovers_away  \\\n",
      "1022                  18                  NaN                   NaN   \n",
      "1023                  18                  NaN                   NaN   \n",
      "3745                  17                  1.0                  22.0   \n",
      "3746                  17                  1.0                  22.0   \n",
      "6860                  10                  1.0                  23.0   \n",
      "6861                  10                  1.0                  23.0   \n",
      "14417                  7                  0.0                  23.0   \n",
      "14418                  7                  0.0                  23.0   \n",
      "15652                  4                  0.0                  21.0   \n",
      "15653                  4                  0.0                  21.0   \n",
      "16746                 11                  0.0                  15.0   \n",
      "16747                 11                  0.0                  15.0   \n",
      "19193                  4                  0.0                  18.0   \n",
      "19194                  4                  0.0                  18.0   \n",
      "21610                  8                  0.0                  19.0   \n",
      "21611                  8                  0.0                  19.0   \n",
      "23900                 16                  0.0                   9.0   \n",
      "23901                 16                  0.0                   9.0   \n",
      "28269                 19                  0.0                  12.0   \n",
      "28270                 19                  0.0                  12.0   \n",
      "\n",
      "       team_rebounds_away  pts_off_to_away  \n",
      "1022                  NaN              NaN  \n",
      "1023                  NaN              NaN  \n",
      "3745                  5.0             24.0  \n",
      "3746                  5.0             24.0  \n",
      "6860                 11.0             31.0  \n",
      "6861                 11.0             31.0  \n",
      "14417                 7.0             31.0  \n",
      "14418                 7.0             31.0  \n",
      "15652                11.0             29.0  \n",
      "15653                11.0             29.0  \n",
      "16746                 7.0             26.0  \n",
      "16747                 7.0             26.0  \n",
      "19193                 6.0             18.0  \n",
      "19194                 6.0             18.0  \n",
      "21610                 4.0             25.0  \n",
      "21611                 4.0             25.0  \n",
      "23900                 5.0             12.0  \n",
      "23901                 5.0             12.0  \n",
      "28269                 3.0             20.0  \n",
      "28270                 3.0             20.0  \n",
      "\n",
      "[20 rows x 26 columns]\n",
      "Duplicados eliminados.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\103853998.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  OtrasEstadisticas['game_id'].fillna('0', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla OtrasEstadisticas en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV completo\n",
    "OtrasEstadisticas = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\OtrasEstadisticas_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'game_id'\n",
    "if 'game_id' in OtrasEstadisticas.columns:\n",
    "    duplicados = OtrasEstadisticas[OtrasEstadisticas.duplicated(subset=['game_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'game_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        OtrasEstadisticas = OtrasEstadisticas.drop_duplicates(subset=['game_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'game_id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'game_id' no tenga valores nulos y convertir a string\n",
    "OtrasEstadisticas['game_id'].fillna('0', inplace=True)\n",
    "OtrasEstadisticas['game_id'] = OtrasEstadisticas['game_id'].astype(str)\n",
    "\n",
    "# Asegurar que las columnas relevantes de 'team_id_home' y 'team_id_away' no tengan valores nulos y convertir a enteros\n",
    "OtrasEstadisticas['team_id_home'] = pd.to_numeric(OtrasEstadisticas['team_id_home'], errors='coerce')\n",
    "OtrasEstadisticas['team_id_away'] = pd.to_numeric(OtrasEstadisticas['team_id_away'], errors='coerce')\n",
    "\n",
    "# Convertir las demás columnas relevantes a tipo float\n",
    "numeric_columns = [\n",
    "    'pts_paint_home', 'pts_2nd_chance_home', 'pts_fb_home', 'largest_lead_home', 'lead_changes', 'times_tied', \n",
    "    'team_turnovers_home', 'total_turnovers_home', 'team_rebounds_home', 'pts_off_to_home',\n",
    "    'pts_paint_away', 'pts_2nd_chance_away', 'pts_fb_away', 'largest_lead_away', 'team_turnovers_away',\n",
    "    'total_turnovers_away', 'team_rebounds_away', 'pts_off_to_away'\n",
    "]\n",
    "\n",
    "OtrasEstadisticas[numeric_columns] = OtrasEstadisticas[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convertir las columnas de texto a tipo string\n",
    "categorical_columns = [\n",
    "    'league_id', 'team_abbreviation_home', 'team_city_home', 'team_abbreviation_away', 'team_city_away'\n",
    "]\n",
    "\n",
    "OtrasEstadisticas[categorical_columns] = OtrasEstadisticas[categorical_columns].astype(str)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'game_id': types.INTEGER,  # Se usará como PK\n",
    "    'league_id': types.INTEGER,\n",
    "    'team_id_home': types.INTEGER,\n",
    "    'team_abbreviation_home': types.VARCHAR(length=10),\n",
    "    'team_city_home': types.VARCHAR(length=50),\n",
    "    'pts_paint_home': types.FLOAT,\n",
    "    'pts_2nd_chance_home': types.FLOAT,\n",
    "    'pts_fb_home': types.FLOAT,\n",
    "    'largest_lead_home': types.FLOAT,\n",
    "    'lead_changes': types.FLOAT,\n",
    "    'times_tied': types.FLOAT,\n",
    "    'team_turnovers_home': types.FLOAT,\n",
    "    'total_turnovers_home': types.FLOAT,\n",
    "    'team_rebounds_home': types.FLOAT,\n",
    "    'pts_off_to_home': types.FLOAT,\n",
    "    'team_id_away': types.INTEGER,\n",
    "    'team_abbreviation_away': types.VARCHAR(length=10),\n",
    "    'team_city_away': types.VARCHAR(length=50),\n",
    "    'pts_paint_away': types.FLOAT,\n",
    "    'pts_2nd_chance_away': types.FLOAT,\n",
    "    'pts_fb_away': types.FLOAT,\n",
    "    'largest_lead_away': types.FLOAT,\n",
    "    'team_turnovers_away': types.FLOAT,\n",
    "    'total_turnovers_away': types.FLOAT,\n",
    "    'team_rebounds_away': types.FLOAT,\n",
    "    'pts_off_to_away': types.FLOAT\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada OtrasEstadisticas\n",
    "OtrasEstadisticas.to_sql('OtrasEstadisticas', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla OtrasEstadisticas en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que game_id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer game_id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE OtrasEstadisticas\n",
    "        ALTER COLUMN game_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla OtrasEstadisticas\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE OtrasEstadisticas\n",
    "        ADD CONSTRAINT PK_game_id PRIMARY KEY (game_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron duplicados en la columna 'game_id':\n",
      "        game_id  league_id  team_id_home  team_abbreviation_home  \\\n",
      "1022   39600001          0    1610616834                     NaN   \n",
      "1023   39600001          0    1610616834                     NaN   \n",
      "3745   39900001          0    1610616833                     NaN   \n",
      "3746   39900001          0    1610616833                     NaN   \n",
      "6860   30200001          0    1610616834                     NaN   \n",
      "6861   30200001          0    1610616834                     NaN   \n",
      "14417  30900001          0    1610616833                     NaN   \n",
      "14418  30900001          0    1610616833                     NaN   \n",
      "15652  31000001          0    1610616834                     NaN   \n",
      "15653  31000001          0    1610616834                     NaN   \n",
      "16746  31200001          0    1610616833                     NaN   \n",
      "16747  31200001          0    1610616833                     NaN   \n",
      "19193  31400001          0    1610616834                     NaN   \n",
      "19194  31400001          0    1610616834                     NaN   \n",
      "21610  31600001          0    1610616834                     NaN   \n",
      "21611  31600001          0    1610616834                     NaN   \n",
      "23900  31800001          0    1610616833                     NaN   \n",
      "23901  31800001          0    1610616833                     NaN   \n",
      "28269  32200001          0    1610616834                     NaN   \n",
      "28270  32200001          0    1610616834                     NaN   \n",
      "\n",
      "       team_city_home  pts_paint_home  pts_2nd_chance_home  pts_fb_home  \\\n",
      "1022              NaN              74                   10           26   \n",
      "1023              NaN              74                   10           26   \n",
      "3745              NaN              54                   29           21   \n",
      "3746              NaN              54                   29           21   \n",
      "6860              NaN              88                   21           32   \n",
      "6861              NaN              88                   21           32   \n",
      "14417             NaN              88                   11           56   \n",
      "14418             NaN              88                   11           56   \n",
      "15652             NaN              80                   35           43   \n",
      "15653             NaN              80                   35           43   \n",
      "16746             NaN              66                   15           21   \n",
      "16747             NaN              66                   15           21   \n",
      "19193             NaN              68                   22           59   \n",
      "19194             NaN              68                   22           59   \n",
      "21610             NaN             120                   23          106   \n",
      "21611             NaN             120                   23          106   \n",
      "23900             NaN              78                   26           37   \n",
      "23901             NaN              78                   26           37   \n",
      "28269             NaN             118                   15           27   \n",
      "28270             NaN             118                   15           27   \n",
      "\n",
      "       largest_lead_home  lead_changes  ...  team_abbreviation_away  \\\n",
      "1022                  23             4  ...                     NaN   \n",
      "1023                  23             4  ...                     NaN   \n",
      "3745                   2             2  ...                     NaN   \n",
      "3746                   2             2  ...                     NaN   \n",
      "6860                  11            26  ...                     NaN   \n",
      "6861                  11            26  ...                     NaN   \n",
      "14417                 16            13  ...                     NaN   \n",
      "14418                 16            13  ...                     NaN   \n",
      "15652                 17             1  ...                     NaN   \n",
      "15653                 17             1  ...                     NaN   \n",
      "16746                  2            22  ...                     NaN   \n",
      "16747                  2            22  ...                     NaN   \n",
      "19193                 20            17  ...                     NaN   \n",
      "19194                 20            17  ...                     NaN   \n",
      "21610                 15            16  ...                     NaN   \n",
      "21611                 15            16  ...                     NaN   \n",
      "23900                 20             9  ...                     NaN   \n",
      "23901                 20             9  ...                     NaN   \n",
      "28269                  4            24  ...                     NaN   \n",
      "28270                  4            24  ...                     NaN   \n",
      "\n",
      "       team_city_away  pts_paint_away  pts_2nd_chance_away  pts_fb_away  \\\n",
      "1022              NaN              80                   38           24   \n",
      "1023              NaN              80                   38           24   \n",
      "3745              NaN              86                   34           26   \n",
      "3746              NaN              86                   34           26   \n",
      "6860              NaN              64                   15           31   \n",
      "6861              NaN              64                   15           31   \n",
      "14417             NaN              74                   21           24   \n",
      "14418             NaN              74                   21           24   \n",
      "15652             NaN              86                   22           53   \n",
      "15653             NaN              86                   22           53   \n",
      "16746             NaN              88                   13           38   \n",
      "16747             NaN              88                   13           38   \n",
      "19193             NaN              82                   25           61   \n",
      "19194             NaN              82                   25           61   \n",
      "21610             NaN             106                   14          107   \n",
      "21611             NaN             106                   14          107   \n",
      "23900             NaN              62                   19           33   \n",
      "23901             NaN              62                   19           33   \n",
      "28269             NaN              88                   14           33   \n",
      "28270             NaN              88                   14           33   \n",
      "\n",
      "       largest_lead_away  team_turnovers_away  total_turnovers_away  \\\n",
      "1022                  18                  NaN                   NaN   \n",
      "1023                  18                  NaN                   NaN   \n",
      "3745                  17                  1.0                  22.0   \n",
      "3746                  17                  1.0                  22.0   \n",
      "6860                  10                  1.0                  23.0   \n",
      "6861                  10                  1.0                  23.0   \n",
      "14417                  7                  0.0                  23.0   \n",
      "14418                  7                  0.0                  23.0   \n",
      "15652                  4                  0.0                  21.0   \n",
      "15653                  4                  0.0                  21.0   \n",
      "16746                 11                  0.0                  15.0   \n",
      "16747                 11                  0.0                  15.0   \n",
      "19193                  4                  0.0                  18.0   \n",
      "19194                  4                  0.0                  18.0   \n",
      "21610                  8                  0.0                  19.0   \n",
      "21611                  8                  0.0                  19.0   \n",
      "23900                 16                  0.0                   9.0   \n",
      "23901                 16                  0.0                   9.0   \n",
      "28269                 19                  0.0                  12.0   \n",
      "28270                 19                  0.0                  12.0   \n",
      "\n",
      "       team_rebounds_away  pts_off_to_away  \n",
      "1022                  NaN              NaN  \n",
      "1023                  NaN              NaN  \n",
      "3745                  5.0             24.0  \n",
      "3746                  5.0             24.0  \n",
      "6860                 11.0             31.0  \n",
      "6861                 11.0             31.0  \n",
      "14417                 7.0             31.0  \n",
      "14418                 7.0             31.0  \n",
      "15652                11.0             29.0  \n",
      "15653                11.0             29.0  \n",
      "16746                 7.0             26.0  \n",
      "16747                 7.0             26.0  \n",
      "19193                 6.0             18.0  \n",
      "19194                 6.0             18.0  \n",
      "21610                 4.0             25.0  \n",
      "21611                 4.0             25.0  \n",
      "23900                 5.0             12.0  \n",
      "23901                 5.0             12.0  \n",
      "28269                 3.0             20.0  \n",
      "28270                 3.0             20.0  \n",
      "\n",
      "[20 rows x 26 columns]\n",
      "Duplicados eliminados.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\103853998.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  OtrasEstadisticas['game_id'].fillna('0', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla OtrasEstadisticas en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV completo\n",
    "OtrasEstadisticas = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\OtrasEstadisticas_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'game_id'\n",
    "if 'game_id' in OtrasEstadisticas.columns:\n",
    "    duplicados = OtrasEstadisticas[OtrasEstadisticas.duplicated(subset=['game_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'game_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        OtrasEstadisticas = OtrasEstadisticas.drop_duplicates(subset=['game_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'game_id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'game_id' no tenga valores nulos y convertir a string\n",
    "OtrasEstadisticas['game_id'].fillna('0', inplace=True)\n",
    "OtrasEstadisticas['game_id'] = OtrasEstadisticas['game_id'].astype(str)\n",
    "\n",
    "# Asegurar que las columnas relevantes de 'team_id_home' y 'team_id_away' no tengan valores nulos y convertir a enteros\n",
    "OtrasEstadisticas['team_id_home'] = pd.to_numeric(OtrasEstadisticas['team_id_home'], errors='coerce')\n",
    "OtrasEstadisticas['team_id_away'] = pd.to_numeric(OtrasEstadisticas['team_id_away'], errors='coerce')\n",
    "\n",
    "# Convertir las demás columnas relevantes a tipo float\n",
    "numeric_columns = [\n",
    "    'pts_paint_home', 'pts_2nd_chance_home', 'pts_fb_home', 'largest_lead_home', 'lead_changes', 'times_tied', \n",
    "    'team_turnovers_home', 'total_turnovers_home', 'team_rebounds_home', 'pts_off_to_home',\n",
    "    'pts_paint_away', 'pts_2nd_chance_away', 'pts_fb_away', 'largest_lead_away', 'team_turnovers_away',\n",
    "    'total_turnovers_away', 'team_rebounds_away', 'pts_off_to_away'\n",
    "]\n",
    "\n",
    "OtrasEstadisticas[numeric_columns] = OtrasEstadisticas[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convertir las columnas de texto a tipo string\n",
    "categorical_columns = [\n",
    "    'league_id', 'team_abbreviation_home', 'team_city_home', 'team_abbreviation_away', 'team_city_away'\n",
    "]\n",
    "\n",
    "OtrasEstadisticas[categorical_columns] = OtrasEstadisticas[categorical_columns].astype(str)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'game_id': types.INTEGER,  # Se usará como PK\n",
    "    'league_id': types.INTEGER,\n",
    "    'team_id_home': types.INTEGER,\n",
    "    'team_abbreviation_home': types.VARCHAR(length=10),\n",
    "    'team_city_home': types.VARCHAR(length=50),\n",
    "    'pts_paint_home': types.FLOAT,\n",
    "    'pts_2nd_chance_home': types.FLOAT,\n",
    "    'pts_fb_home': types.FLOAT,\n",
    "    'largest_lead_home': types.FLOAT,\n",
    "    'lead_changes': types.FLOAT,\n",
    "    'times_tied': types.FLOAT,\n",
    "    'team_turnovers_home': types.FLOAT,\n",
    "    'total_turnovers_home': types.FLOAT,\n",
    "    'team_rebounds_home': types.FLOAT,\n",
    "    'pts_off_to_home': types.FLOAT,\n",
    "    'team_id_away': types.INTEGER,\n",
    "    'team_abbreviation_away': types.VARCHAR(length=10),\n",
    "    'team_city_away': types.VARCHAR(length=50),\n",
    "    'pts_paint_away': types.FLOAT,\n",
    "    'pts_2nd_chance_away': types.FLOAT,\n",
    "    'pts_fb_away': types.FLOAT,\n",
    "    'largest_lead_away': types.FLOAT,\n",
    "    'team_turnovers_away': types.FLOAT,\n",
    "    'total_turnovers_away': types.FLOAT,\n",
    "    'team_rebounds_away': types.FLOAT,\n",
    "    'pts_off_to_away': types.FLOAT\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada OtrasEstadisticas\n",
    "OtrasEstadisticas.to_sql('OtrasEstadisticas', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla OtrasEstadisticas en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que game_id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer game_id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE OtrasEstadisticas\n",
    "        ALTER COLUMN game_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla OtrasEstadisticas\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE OtrasEstadisticas\n",
    "        ADD CONSTRAINT PK_game_id PRIMARY KEY (game_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_12624\\2573995447.py:6: DtypeWarning: Columns (7,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  PuntuacionDeLinea = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\PuntuacionDeLinea_transformado.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron duplicados en la columna 'game_id':\n",
      "      game_date_est  game_sequence   game_id  team_id_home  \\\n",
      "1613     1951-03-02            1.0  35000001    1610616833   \n",
      "1614     1951-03-02            1.0  35000001    1610616833   \n",
      "1921     1952-02-11            1.0  35100001    1610616834   \n",
      "1922     1952-02-11            1.0  35100001    1610616834   \n",
      "2244     1953-01-13            1.0  35200001    1610616833   \n",
      "...             ...            ...       ...           ...   \n",
      "50922    2017-02-19            1.0  31600001    1610616834   \n",
      "53393    2019-02-17            1.0  31800001    1610616833   \n",
      "53394    2019-02-17            1.0  31800001    1610616833   \n",
      "58051    2023-02-19            1.0  32200001    1610616834   \n",
      "58052    2023-02-19            1.0  32200001    1610616834   \n",
      "\n",
      "       team_abbreviation_home  team_city_name_home  team_nickname_home  \\\n",
      "1613                      NaN                  NaN                 NaN   \n",
      "1614                      NaN                  NaN                 NaN   \n",
      "1921                      NaN                  NaN                 NaN   \n",
      "1922                      NaN                  NaN                 NaN   \n",
      "2244                      NaN                  NaN                 NaN   \n",
      "...                       ...                  ...                 ...   \n",
      "50922                     NaN                  NaN                 NaN   \n",
      "53393                     NaN                  NaN                 NaN   \n",
      "53394                     NaN                  NaN                 NaN   \n",
      "58051                     NaN                  NaN                 NaN   \n",
      "58052                     NaN                  NaN                 NaN   \n",
      "\n",
      "      team_wins_losses_home  pts_qtr1_home  pts_qtr2_home  ...  pts_ot2_away  \\\n",
      "1613                    NaN           31.0           22.0  ...           NaN   \n",
      "1614                    NaN           31.0           22.0  ...           NaN   \n",
      "1921                    NaN           22.0           22.0  ...           NaN   \n",
      "1922                    NaN           22.0           22.0  ...           NaN   \n",
      "2244                    NaN           20.0           14.0  ...           NaN   \n",
      "...                     ...            ...            ...  ...           ...   \n",
      "50922                   NaN           48.0           49.0  ...           0.0   \n",
      "53393                   NaN           53.0           42.0  ...           0.0   \n",
      "53394                   NaN           53.0           42.0  ...           0.0   \n",
      "58051                   NaN           46.0           46.0  ...           0.0   \n",
      "58052                   NaN           46.0           46.0  ...           0.0   \n",
      "\n",
      "       pts_ot3_away  pts_ot4_away  pts_ot5_away  pts_ot6_away  pts_ot7_away  \\\n",
      "1613            NaN           NaN           NaN           NaN           NaN   \n",
      "1614            NaN           NaN           NaN           NaN           NaN   \n",
      "1921            NaN           NaN           NaN           NaN           NaN   \n",
      "1922            NaN           NaN           NaN           NaN           NaN   \n",
      "2244            NaN           NaN           NaN           NaN           NaN   \n",
      "...             ...           ...           ...           ...           ...   \n",
      "50922           0.0           0.0           0.0           0.0           0.0   \n",
      "53393           0.0           0.0           0.0           0.0           0.0   \n",
      "53394           0.0           0.0           0.0           0.0           0.0   \n",
      "58051           0.0           0.0           0.0           0.0           0.0   \n",
      "58052           0.0           0.0           0.0           0.0           0.0   \n",
      "\n",
      "       pts_ot8_away  pts_ot9_away  pts_ot10_away  pts_away  \n",
      "1613            NaN           NaN            NaN      94.0  \n",
      "1614            NaN           NaN            NaN      94.0  \n",
      "1921            NaN           NaN            NaN     108.0  \n",
      "1922            NaN           NaN            NaN     108.0  \n",
      "2244            NaN           NaN            NaN      79.0  \n",
      "...             ...           ...            ...       ...  \n",
      "50922           0.0           0.0            0.0     182.0  \n",
      "53393           0.0           0.0            0.0     178.0  \n",
      "53394           0.0           0.0            0.0     178.0  \n",
      "58051           0.0           0.0            0.0     184.0  \n",
      "58052           0.0           0.0            0.0     184.0  \n",
      "\n",
      "[80 rows x 43 columns]\n",
      "Duplicados eliminados.\n",
      "Datos exportados exitosamente a la tabla PuntuacionDeLinea en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV completo\n",
    "PuntuacionDeLinea = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\PuntuacionDeLinea_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'game_id'\n",
    "if 'game_id' in PuntuacionDeLinea.columns:\n",
    "    duplicados = PuntuacionDeLinea[PuntuacionDeLinea.duplicated(subset=['game_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'game_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        PuntuacionDeLinea = PuntuacionDeLinea.drop_duplicates(subset=['game_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'game_id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que las columnas relevantes no tengan valores nulos y convertir los tipos de datos apropiados\n",
    "PuntuacionDeLinea['game_id'] = PuntuacionDeLinea['game_id'].fillna('0').astype(str)\n",
    "PuntuacionDeLinea['game_date_est'] = pd.to_datetime(PuntuacionDeLinea['game_date_est'], errors='coerce')\n",
    "\n",
    "# Convertir columnas numéricas a tipo float y manejar valores nulos\n",
    "numeric_columns = [\n",
    "    'pts_qtr1_home', 'pts_qtr2_home', 'pts_qtr3_home', 'pts_qtr4_home', 'pts_ot1_home', 'pts_ot2_home',\n",
    "    'pts_ot3_home', 'pts_ot4_home', 'pts_ot5_home', 'pts_ot6_home', 'pts_ot7_home', 'pts_ot8_home', \n",
    "    'pts_ot9_home', 'pts_ot10_home', 'pts_home', 'pts_qtr1_away', 'pts_qtr2_away', 'pts_qtr3_away', \n",
    "    'pts_qtr4_away', 'pts_ot1_away', 'pts_ot2_away', 'pts_ot3_away', 'pts_ot4_away', 'pts_ot5_away',\n",
    "    'pts_ot6_away', 'pts_ot7_away', 'pts_ot8_away', 'pts_ot9_away', 'pts_ot10_away', 'pts_away'\n",
    "]\n",
    "\n",
    "PuntuacionDeLinea[numeric_columns] = PuntuacionDeLinea[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convertir las columnas de texto a tipo string\n",
    "categorical_columns = [\n",
    "    'team_abbreviation_home', 'team_city_name_home', 'team_nickname_home', 'team_wins_losses_home', \n",
    "    'team_abbreviation_away', 'team_city_name_away', 'team_nickname_away', 'team_wins_losses_away'\n",
    "]\n",
    "\n",
    "PuntuacionDeLinea[categorical_columns] = PuntuacionDeLinea[categorical_columns].astype(str)\n",
    "\n",
    "# Asegurar que los identificadores de equipo sean enteros\n",
    "PuntuacionDeLinea['team_id_home'] = pd.to_numeric(PuntuacionDeLinea['team_id_home'], errors='coerce')\n",
    "PuntuacionDeLinea['team_id_away'] = pd.to_numeric(PuntuacionDeLinea['team_id_away'], errors='coerce')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'game_id': types.INTEGER,  # Se usará como PK\n",
    "    'game_date_est': types.Date,\n",
    "    'game_sequence': types.INTEGER,\n",
    "    'team_id_home': types.INTEGER,\n",
    "    'team_abbreviation_home': types.VARCHAR(length=10),\n",
    "    'team_city_name_home': types.VARCHAR(length=50),\n",
    "    'team_nickname_home': types.VARCHAR(length=50),\n",
    "    'team_wins_losses_home': types.VARCHAR(length=10),\n",
    "    'pts_qtr1_home': types.FLOAT,\n",
    "    'pts_qtr2_home': types.FLOAT,\n",
    "    'pts_qtr3_home': types.FLOAT,\n",
    "    'pts_qtr4_home': types.FLOAT,\n",
    "    'pts_ot1_home': types.FLOAT,\n",
    "    'pts_ot2_home': types.FLOAT,\n",
    "    'pts_ot3_home': types.FLOAT,\n",
    "    'pts_ot4_home': types.FLOAT,\n",
    "    'pts_ot5_home': types.FLOAT,\n",
    "    'pts_ot6_home': types.FLOAT,\n",
    "    'pts_ot7_home': types.FLOAT,\n",
    "    'pts_ot8_home': types.FLOAT,\n",
    "    'pts_ot9_home': types.FLOAT,\n",
    "    'pts_ot10_home': types.FLOAT,\n",
    "    'pts_home': types.FLOAT,\n",
    "    'team_id_away': types.INTEGER,\n",
    "    'team_abbreviation_away': types.VARCHAR(length=10),\n",
    "    'team_city_name_away': types.VARCHAR(length=50),\n",
    "    'team_nickname_away': types.VARCHAR(length=50),\n",
    "    'team_wins_losses_away': types.VARCHAR(length=10),\n",
    "    'pts_qtr1_away': types.FLOAT,\n",
    "    'pts_qtr2_away': types.FLOAT,\n",
    "    'pts_qtr3_away': types.FLOAT,\n",
    "    'pts_qtr4_away': types.FLOAT,\n",
    "    'pts_ot1_away': types.FLOAT,\n",
    "    'pts_ot2_away': types.FLOAT,\n",
    "    'pts_ot3_away': types.FLOAT,\n",
    "    'pts_ot4_away': types.FLOAT,\n",
    "    'pts_ot5_away': types.FLOAT,\n",
    "    'pts_ot6_away': types.FLOAT,\n",
    "    'pts_ot7_away': types.FLOAT,\n",
    "    'pts_ot8_away': types.FLOAT,\n",
    "    'pts_ot9_away': types.FLOAT,\n",
    "    'pts_ot10_away': types.FLOAT,\n",
    "    'pts_away': types.FLOAT\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada PuntuacionDeLinea\n",
    "PuntuacionDeLinea.to_sql('PuntuacionDeLinea', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla PuntuacionDeLinea en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que game_id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer game_id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE PuntuacionDeLinea\n",
    "        ALTER COLUMN game_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla PuntuacionDeLinea\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE PuntuacionDeLinea\n",
    "        ADD CONSTRAINT PK_game_id PRIMARY KEY (game_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron duplicados en la columna 'game_id':\n",
      "             game_date_est  game_sequence   game_id  game_status_id  \\\n",
      "1613   1951-03-02 00:00:00            1.0  35000001               3   \n",
      "1614   1951-03-02 00:00:00            1.0  35000001               3   \n",
      "1921   1952-02-11 00:00:00            1.0  35100001               3   \n",
      "1922   1952-02-11 00:00:00            1.0  35100001               3   \n",
      "2244   1953-01-13 00:00:00            1.0  35200001               3   \n",
      "...                    ...            ...       ...             ...   \n",
      "55599           2021-03-07            1.0  32000001               3   \n",
      "57110           2022-11-25           14.0  22200285               3   \n",
      "57111           2022-11-25           14.0  22200285               3   \n",
      "58108           2023-02-19            1.0  32200001               3   \n",
      "58109           2023-02-19            1.0  32200001               3   \n",
      "\n",
      "      game_status_text  gamecode  home_team_id  visitor_team_id  season  \\\n",
      "1613               NaN       NaN    1610616833       1610616834    1950   \n",
      "1614               NaN       NaN    1610616833       1610616834    1950   \n",
      "1921               NaN       NaN    1610616833       1610616834    1951   \n",
      "1922               NaN       NaN    1610616833       1610616834    1951   \n",
      "2244               NaN       NaN    1610616833       1610616834    1952   \n",
      "...                ...       ...           ...              ...     ...   \n",
      "55599              NaN       NaN    1610616833       1610616834    2020   \n",
      "57110              NaN       NaN    1610612746       1610612743    2022   \n",
      "57111              NaN       NaN    1610612746       1610612743    2022   \n",
      "58108              NaN       NaN    1610616834       1610616833    2022   \n",
      "58109              NaN       NaN    1610616834       1610616833    2022   \n",
      "\n",
      "       live_period live_pc_time  natl_tv_broadcaster_abbreviation  \\\n",
      "1613             4          NaN                               NaN   \n",
      "1614             4          NaN                               NaN   \n",
      "1921             4          NaN                               NaN   \n",
      "1922             4          NaN                               NaN   \n",
      "2244             4          NaN                               NaN   \n",
      "...            ...          ...                               ...   \n",
      "55599            4          NaN                               NaN   \n",
      "57110            4          NaN                               NaN   \n",
      "57111            4          NaN                               NaN   \n",
      "58108            4          NaN                               NaN   \n",
      "58109            4          NaN                               NaN   \n",
      "\n",
      "       live_period_time_bcast  wh_status  \n",
      "1613                      NaN          1  \n",
      "1614                      NaN          1  \n",
      "1921                      NaN          1  \n",
      "1922                      NaN          1  \n",
      "2244                      NaN          1  \n",
      "...                       ...        ...  \n",
      "55599                     NaN          1  \n",
      "57110                     NaN          1  \n",
      "57111                     NaN          1  \n",
      "58108                     NaN          1  \n",
      "58109                     NaN          1  \n",
      "\n",
      "[174 rows x 14 columns]\n",
      "Duplicados eliminados.\n",
      "Datos exportados exitosamente a la tabla ResumenDelJuego en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV completo\n",
    "ResumenDelJuego = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\ResumenDelJuego_transformado.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'game_id'\n",
    "if 'game_id' in ResumenDelJuego.columns:\n",
    "    duplicados = ResumenDelJuego[ResumenDelJuego.duplicated(subset=['game_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'game_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        ResumenDelJuego = ResumenDelJuego.drop_duplicates(subset=['game_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'game_id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que las columnas relevantes no tengan valores nulos y convertir los tipos de datos apropiados\n",
    "ResumenDelJuego['game_id'] = ResumenDelJuego['game_id'].fillna('0').astype(str)\n",
    "ResumenDelJuego['game_date_est'] = pd.to_datetime(ResumenDelJuego['game_date_est'], errors='coerce')\n",
    "\n",
    "# Convertir columnas numéricas a tipo float y manejar valores nulos\n",
    "numeric_columns = [\n",
    "    'game_sequence', 'game_status_id', 'home_team_id', 'visitor_team_id', 'season', 'live_period',\n",
    "    'live_pc_time', 'live_period_time_bcast'\n",
    "]\n",
    "\n",
    "ResumenDelJuego[numeric_columns] = ResumenDelJuego[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convertir las columnas de texto a tipo string\n",
    "categorical_columns = [\n",
    "    'game_status_text', 'gamecode', 'natl_tv_broadcaster_abbreviation', 'wh_status'\n",
    "]\n",
    "\n",
    "ResumenDelJuego[categorical_columns] = ResumenDelJuego[categorical_columns].astype(str)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'game_id': types.INTEGER,  # Se usará como PK\n",
    "    'game_date_est': types.Date,\n",
    "    'game_sequence': types.INTEGER,\n",
    "    'game_status_id': types.INTEGER,\n",
    "    'game_status_text': types.VARCHAR(length=50),\n",
    "    'gamecode': types.VARCHAR(length=20),\n",
    "    'home_team_id': types.INTEGER,\n",
    "    'visitor_team_id': types.INTEGER,\n",
    "    'season': types.INTEGER,\n",
    "    'live_period': types.INTEGER,\n",
    "    'live_pc_time': types.FLOAT,\n",
    "    'natl_tv_broadcaster_abbreviation': types.VARCHAR(length=10),\n",
    "    'live_period_time_bcast': types.FLOAT,\n",
    "    'wh_status': types.VARCHAR(length=20)\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada ResumenDelJuego\n",
    "ResumenDelJuego.to_sql('ResumenDelJuego', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla ResumenDelJuego en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que game_id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer game_id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE ResumenDelJuego\n",
    "        ALTER COLUMN game_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla ResumenDelJuego\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE ResumenDelJuego\n",
    "        ADD CONSTRAINT PK_game_id PRIMARY KEY (game_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla team_data en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV completo\n",
    "team_data = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\team.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'id'\n",
    "if 'id' in team_data.columns:\n",
    "    duplicados = team_data[team_data.duplicated(subset=['id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        team_data = team_data.drop_duplicates(subset=['id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'id' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que las columnas relevantes no tengan valores nulos y convertir los tipos de datos apropiados\n",
    "team_data['id'] = team_data['id'].fillna('0').astype(str)\n",
    "team_data['year_founded'] = pd.to_numeric(team_data['year_founded'], errors='coerce')\n",
    "\n",
    "# Convertir las columnas de texto a tipo string\n",
    "categorical_columns = [\n",
    "    'full_name', 'abbreviation', 'nickname', 'city', 'state'\n",
    "]\n",
    "\n",
    "team_data[categorical_columns] = team_data[categorical_columns].astype(str)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Especificar los tipos de datos para cada columna en SQL Server\n",
    "dtype_sql = {\n",
    "    'id': types.INTEGER,  # Se usará como PK\n",
    "    'full_name': types.VARCHAR(length=100),\n",
    "    'abbreviation': types.VARCHAR(length=10),\n",
    "    'nickname': types.VARCHAR(length=50),\n",
    "    'city': types.VARCHAR(length=50),\n",
    "    'state': types.VARCHAR(length=50),\n",
    "    'year_founded': types.INTEGER\n",
    "}\n",
    "\n",
    "# Exportar el DataFrame a una tabla SQL llamada team_data\n",
    "team_data.to_sql('team_data', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla team_data en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que id es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer id como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE team_data\n",
    "        ALTER COLUMN id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla team_data\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE team_data\n",
    "        ADD CONSTRAINT PK_id PRIMARY KEY (id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron duplicados en la columna 'team_id':\n",
      "       team_id               city     nickname  year_founded  year_active_till\n",
      "0   1610612737            Atlanta        Hawks          1968              2019\n",
      "1   1610612737          St. Louis        Hawks          1955              1967\n",
      "2   1610612737          Milwaukee        Hawks          1951              1954\n",
      "3   1610612737         Tri-Cities   Blackhawks          1949              1950\n",
      "7   1610612744       Golden State     Warriors          1971              2019\n",
      "8   1610612744      San Francisco     Warriors          1962              1970\n",
      "9   1610612744       Philadelphia     Warriors          1946              1961\n",
      "10  1610612745            Houston      Rockets          1971              2019\n",
      "11  1610612745          San Diego      Rockets          1967              1970\n",
      "12  1610612746        Los Angeles     Clippers          1984              2019\n",
      "13  1610612746          San Diego     Clippers          1978              1983\n",
      "14  1610612746            Buffalo       Braves          1970              1977\n",
      "15  1610612747        Los Angeles       Lakers          1960              2019\n",
      "16  1610612747        Minneapolis       Lakers          1948              1959\n",
      "20  1610612751           Brooklyn         Nets          2012              2019\n",
      "21  1610612751         New Jersey         Nets          1977              2011\n",
      "22  1610612751           New York         Nets          1976              1976\n",
      "24  1610612755       Philadelphia        76ers          1963              2019\n",
      "25  1610612755           Syracuse    Nationals          1949              1962\n",
      "28  1610612758         Sacramento        Kings          1985              2019\n",
      "29  1610612758        Kansas City        Kings          1975              1984\n",
      "30  1610612758  Kansas City-Omaha        Kings          1972              1974\n",
      "31  1610612758         Cincinnati       Royals          1957              1971\n",
      "32  1610612758          Rochester       Royals          1948              1956\n",
      "34  1610612760      Oklahoma City      Thunder          2008              2019\n",
      "35  1610612760            Seattle  SuperSonics          1967              2007\n",
      "37  1610612762               Utah         Jazz          1979              2019\n",
      "38  1610612762        New Orleans         Jazz          1974              1978\n",
      "39  1610612763            Memphis    Grizzlies          2001              2019\n",
      "40  1610612763          Vancouver    Grizzlies          1995              2000\n",
      "41  1610612764         Washington      Wizards          1997              2019\n",
      "42  1610612764         Washington      Bullets          1974              1996\n",
      "43  1610612764            Capital      Bullets          1973              1973\n",
      "44  1610612764          Baltimore      Bullets          1963              1972\n",
      "45  1610612764            Chicago      Zephyrs          1962              1962\n",
      "46  1610612764            Chicago      Packers          1961              1961\n",
      "47  1610612765            Detroit      Pistons          1957              2019\n",
      "48  1610612765  Ft. Wayne Zollner      Pistons          1948              1956\n",
      "49  1610612766          Charlotte      Hornets          2014              2019\n",
      "50  1610612766          Charlotte      Bobcats          2004              2013\n",
      "51  1610612766          Charlotte      Hornets          1988              2001\n",
      "Duplicados eliminados.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_16720\\3785977942.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  TeamHistory['team_id'].fillna('0', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos exportados exitosamente a la tabla TeamHistory en la base de datos NBA\n",
      "Clave primaria agregada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "TeamHistory = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\team_history.csv')\n",
    "\n",
    "# Verificar y eliminar duplicados en la columna 'InventarioID'\n",
    "if 'team_id' in TeamHistory.columns:\n",
    "    duplicados = TeamHistory[TeamHistory.duplicated(subset=['team_id'], keep=False)]\n",
    "    if not duplicados.empty:\n",
    "        print(\"Se encontraron duplicados en la columna 'team_id':\")\n",
    "        print(duplicados)\n",
    "        # Eliminar duplicados\n",
    "        TeamHistory = TeamHistory.drop_duplicates(subset=['team_id'])\n",
    "        print(\"Duplicados eliminados.\")\n",
    "else:\n",
    "    print(\"La columna 'TeamHistory' no existe en el DataFrame.\")\n",
    "\n",
    "# Asegurar que la columna 'InventarioID' no tenga valores nulos y convertir a string\n",
    "TeamHistory['team_id'].fillna('0', inplace=True)\n",
    "TeamHistory['team_id'] = TeamHistory['team_id'].astype(str)\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes')\n",
    "\n",
    "dtype_sql = {\n",
    "    'team_id': types.INTEGER,  # Identificador único del equipo\n",
    "    'city': types.VARCHAR(length=255),  # Ciudad del equipo\n",
    "    'nickname': types.VARCHAR(length=255),  # Apodo del equipo\n",
    "    'year_founded': types.INTEGER,  # Año de fundación\n",
    "    'year_active_till': types.INTEGER  # Último año activo\n",
    "}\n",
    "# Exportar el DataFrame a una tabla SQL llamada TeamHistory\n",
    "TeamHistory.to_sql('TeamHistory', con=engine, if_exists='replace', index=False, dtype=dtype_sql)\n",
    "\n",
    "print(\"Datos exportados exitosamente a la tabla TeamHistory en la base de datos NBA\")\n",
    "\n",
    "# Conectar para agregar PK y asegurarse de que InventarioID es NOT NULL\n",
    "with engine.connect() as connection:\n",
    "    # Establecer InventarioID como NOT NULL\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE TeamHistory\n",
    "        ALTER COLUMN team_id INTEGER NOT NULL;\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Agregar clave primaria a la tabla ComprasFinal2016\n",
    "    connection.execute(text(\"\"\"\n",
    "        ALTER TABLE TeamHistory\n",
    "        ADD CONSTRAINT PK_team_id PRIMARY KEY (team_id);\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Clave primaria agregada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_updates\n",
      "Nombres actualizados exitosamente en la tabla InformacionComunDelJugador donde first_name es NULL.\n",
      "Tabla temporal temp_updates eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "data = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\common_player_info.csv')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_updates'\n",
    "data[['person_id', 'first_name']].to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Actualizar la tabla InformacionComunDelJugador usando la tabla temporal\n",
    "with engine.connect() as connection:\n",
    "    update_query = f\"\"\"\n",
    "    UPDATE InformacionComunDelJugador\n",
    "    SET InformacionComunDelJugador.first_name = temp_updates.first_name\n",
    "    FROM InformacionComunDelJugador\n",
    "    JOIN temp_updates ON InformacionComunDelJugador.person_id = temp_updates.person_id\n",
    "    WHERE InformacionComunDelJugador.first_name IS NULL;\n",
    "    \"\"\"\n",
    "    connection.execute(text(update_query))\n",
    "\n",
    "print(\"Nombres actualizados exitosamente en la tabla InformacionComunDelJugador donde first_name es NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_updates\n",
      "Datos actualizados exitosamente en la tabla InformacionComunDelJugador donde los valores eran NULL.\n",
      "Tabla temporal temp_updates eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "data = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\common_player_info.csv')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_updates'\n",
    "data.to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Actualizar la tabla InformacionComunDelJugador usando la tabla temporal\n",
    "with engine.connect() as connection:\n",
    "    update_query = f\"\"\"\n",
    "    UPDATE InformacionComunDelJugador\n",
    "    SET \n",
    "        InformacionComunDelJugador.first_name = COALESCE(temp_updates.first_name, InformacionComunDelJugador.first_name),\n",
    "        InformacionComunDelJugador.last_name = COALESCE(temp_updates.last_name, InformacionComunDelJugador.last_name),\n",
    "        InformacionComunDelJugador.display_first_last = COALESCE(temp_updates.display_first_last, InformacionComunDelJugador.display_first_last),\n",
    "        InformacionComunDelJugador.display_last_comma_first = COALESCE(temp_updates.display_last_comma_first, InformacionComunDelJugador.display_last_comma_first),\n",
    "        InformacionComunDelJugador.display_fi_last = COALESCE(temp_updates.display_fi_last, InformacionComunDelJugador.display_fi_last),\n",
    "        InformacionComunDelJugador.player_slug = COALESCE(temp_updates.player_slug, InformacionComunDelJugador.player_slug)\n",
    "    FROM InformacionComunDelJugador\n",
    "    JOIN temp_updates ON InformacionComunDelJugador.person_id = temp_updates.person_id\n",
    "    WHERE InformacionComunDelJugador.first_name IS NULL\n",
    "       OR InformacionComunDelJugador.last_name IS NULL\n",
    "       OR InformacionComunDelJugador.display_first_last IS NULL\n",
    "       OR InformacionComunDelJugador.display_last_comma_first IS NULL\n",
    "       OR InformacionComunDelJugador.display_fi_last IS NULL\n",
    "       OR InformacionComunDelJugador.player_slug IS NULL;\n",
    "    \"\"\"\n",
    "    connection.execute(text(update_query))\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla InformacionComunDelJugador donde los valores eran NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_updates\n",
      "Columna first_name actualizada.\n",
      "Columna last_name actualizada.\n",
      "Columna display_first_last actualizada.\n",
      "Columna display_last_comma_first actualizada.\n",
      "Columna display_fi_last actualizada.\n",
      "Columna player_slug actualizada.\n",
      "Datos actualizados exitosamente en la tabla InformacionComunDelJugador donde los valores eran NULL.\n",
      "Tabla temporal temp_updates eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "data = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\common_player_info.csv')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_updates'\n",
    "data.to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Actualizar la tabla InformacionComunDelJugador usando la tabla temporal\n",
    "with engine.connect() as connection:\n",
    "    columns_to_update = ['first_name', 'last_name', 'display_first_last', 'display_last_comma_first', 'display_fi_last', 'player_slug']\n",
    "    for column in columns_to_update:\n",
    "        update_query = f\"\"\"\n",
    "        UPDATE InformacionComunDelJugador\n",
    "        SET InformacionComunDelJugador.{column} = temp_updates.{column}\n",
    "        FROM InformacionComunDelJugador\n",
    "        JOIN temp_updates ON InformacionComunDelJugador.person_id = temp_updates.person_id\n",
    "        WHERE InformacionComunDelJugador.{column} IS NULL;\n",
    "        \"\"\"\n",
    "        connection.execute(text(update_query))\n",
    "        print(f\"Columna {column} actualizada.\")\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla InformacionComunDelJugador donde los valores eran NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_updates\n",
      "Columna first_name actualizada.\n",
      "Columna last_name actualizada.\n",
      "Columna display_first_last actualizada.\n",
      "Columna display_last_comma_first actualizada.\n",
      "Columna display_fi_last actualizada.\n",
      "Columna player_slug actualizada.\n",
      "Datos actualizados exitosamente en la tabla InformacionComunDelJugador donde los valores eran NULL.\n",
      "Tabla temporal temp_updates eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "data = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\common_player_info.csv')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_updates'\n",
    "data.to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Actualizar la tabla InformacionComunDelJugador usando la tabla temporal\n",
    "with engine.connect() as connection:\n",
    "    columns_to_update = ['first_name', 'last_name', 'display_first_last', 'display_last_comma_first', 'display_fi_last', 'player_slug']\n",
    "    for column in columns_to_update:\n",
    "        update_query = f\"\"\"\n",
    "        UPDATE InformacionComunDelJugador\n",
    "        SET InformacionComunDelJugador.{column} = temp_updates.{column}\n",
    "        FROM InformacionComunDelJugador\n",
    "        JOIN temp_updates ON InformacionComunDelJugador.person_id = temp_updates.person_id\n",
    "        WHERE InformacionComunDelJugador.{column} IS NULL;\n",
    "        \"\"\"\n",
    "        connection.execute(text(update_query))\n",
    "        print(f\"Columna {column} actualizada.\")\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla InformacionComunDelJugador donde los valores eran NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_updates\n",
      "Columna last_name actualizada.\n",
      "Columna display_first_last actualizada.\n",
      "Columna display_last_comma_first actualizada.\n",
      "Columna display_fi_last actualizada.\n",
      "Columna player_slug actualizada.\n",
      "Columna school actualizada.\n",
      "Columna country actualizada.\n",
      "Columna last_affiliation actualizada.\n",
      "Columna jersey actualizada.\n",
      "Columna position actualizada.\n",
      "Columna rosterstatus actualizada.\n",
      "Columna games_played_current_season_flag actualizada.\n",
      "Columna team_name actualizada.\n",
      "Columna team_abbreviation actualizada.\n",
      "Columna dleague_flag actualizada.\n",
      "Columna nba_flag actualizada.\n",
      "Columna games_played_flag actualizada.\n",
      "Columna greatest_75_flag actualizada.\n",
      "Datos actualizados exitosamente en la tabla InformacionComunDelJugador donde los valores eran NULL.\n",
      "Tabla temporal temp_updates eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "data = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\common_player_info.csv')\n",
    "\n",
    "# Convertir 'N'/'Y' a 0/1 para las columnas tipo bit\n",
    "data['games_played_current_season_flag'] = data['games_played_current_season_flag'].map({'N': 0, 'Y': 1})\n",
    "data['dleague_flag'] = data['dleague_flag'].map({'N': 0, 'Y': 1})\n",
    "data['nba_flag'] = data['nba_flag'].map({'N': 0, 'Y': 1})\n",
    "data['games_played_flag'] = data['games_played_flag'].map({'N': 0, 'Y': 1})\n",
    "data['greatest_75_flag'] = data['greatest_75_flag'].map({'N': 0, 'Y': 1})\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_updates'\n",
    "data.to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Actualizar la tabla InformacionComunDelJugador usando la tabla temporal\n",
    "with engine.connect() as connection:\n",
    "    columns_to_update = [\n",
    "        'last_name', 'display_first_last', 'display_last_comma_first', 'display_fi_last',\n",
    "        'player_slug', 'school', 'country', 'last_affiliation', 'jersey', 'position',\n",
    "        'rosterstatus', 'games_played_current_season_flag', 'team_name', 'team_abbreviation',\n",
    "        'dleague_flag', 'nba_flag', 'games_played_flag', 'greatest_75_flag'\n",
    "    ]\n",
    "    for column in columns_to_update:\n",
    "        update_query = f\"\"\"\n",
    "        UPDATE InformacionComunDelJugador\n",
    "        SET InformacionComunDelJugador.{column} = temp_updates.{column}\n",
    "        FROM InformacionComunDelJugador\n",
    "        JOIN temp_updates ON InformacionComunDelJugador.person_id = temp_updates.person_id\n",
    "        WHERE InformacionComunDelJugador.{column} IS NULL;\n",
    "        \"\"\"\n",
    "        connection.execute(text(update_query))\n",
    "        print(f\"Columna {column} actualizada.\")\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla InformacionComunDelJugador donde los valores eran NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_draft_combine_stats\n",
      "Columna first_name actualizada.\n",
      "Columna last_name actualizada.\n",
      "Columna player_name actualizada.\n",
      "Columna position actualizada.\n",
      "Columna standing_reach_ft_in actualizada.\n",
      "Datos actualizados exitosamente en la tabla BorradorDeEstadsticasCombinadas donde los valores eran NULL.\n",
      "Tabla temporal temp_draft_combine_stats eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "draft_combine_stats = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\draft_combine_stats.csv')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_draft_combine_stats'\n",
    "draft_combine_stats.to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Asumimos que las tablas tienen una columna común llamada 'player_name' para la unión\n",
    "common_column = 'player_name'\n",
    "\n",
    "# Actualizar las columnas en la tabla BorradorDeEstadsticasCombinadas usando la tabla temporal\n",
    "columns_to_update = [\n",
    "    'first_name', 'last_name', 'player_name', 'position', 'standing_reach_ft_in'\n",
    "]\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    for column in columns_to_update:\n",
    "        update_query = f\"\"\"\n",
    "        UPDATE BorradorDeEstadsticasCombinadas\n",
    "        SET BorradorDeEstadsticasCombinadas.{column} = temp_draft_combine_stats.{column}\n",
    "        FROM BorradorDeEstadsticasCombinadas\n",
    "        JOIN temp_draft_combine_stats ON BorradorDeEstadsticasCombinadas.{common_column} = temp_draft_combine_stats.{common_column}\n",
    "        WHERE BorradorDeEstadsticasCombinadas.{column} IS NULL;\n",
    "        \"\"\"\n",
    "        connection.execute(text(update_query))\n",
    "        print(f\"Columna {column} actualizada.\")\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla BorradorDeEstadsticasCombinadas donde los valores eran NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_draft_combine_stats\n",
      "Columna first_name actualizada.\n",
      "Columna last_name actualizada.\n",
      "Columna player_name actualizada.\n",
      "Columna position actualizada.\n",
      "Columna standing_reach_ft_in actualizada.\n",
      "Datos actualizados exitosamente en la tabla BorradorDeEstadsticasCombinadas donde los valores eran NULL.\n",
      "Tabla temporal temp_draft_combine_stats eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "draft_combine_stats = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\draft_combine_stats.csv')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_draft_combine_stats'\n",
    "draft_combine_stats.to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Actualizar las columnas en la tabla BorradorDeEstadsticasCombinadas usando la tabla temporal\n",
    "columns_to_update = [\n",
    "    'first_name', 'last_name', 'player_name', 'position', 'standing_reach_ft_in'\n",
    "]\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    for column in columns_to_update:\n",
    "        update_query = f\"\"\"\n",
    "        UPDATE BorradorDeEstadsticasCombinadas\n",
    "        SET BorradorDeEstadsticasCombinadas.{column} = temp_draft_combine_stats.{column}\n",
    "        FROM BorradorDeEstadsticasCombinadas\n",
    "        JOIN temp_draft_combine_stats ON BorradorDeEstadsticasCombinadas.player_name = temp_draft_combine_stats.player_name\n",
    "        WHERE BorradorDeEstadsticasCombinadas.{column} IS NULL;\n",
    "        \"\"\"\n",
    "        connection.execute(text(update_query))\n",
    "        print(f\"Columna {column} actualizada.\")\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla BorradorDeEstadsticasCombinadas donde los valores eran NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_draft_combine_stats\n",
      "Columna first_name actualizada.\n",
      "Columna last_name actualizada.\n",
      "Columna player_name actualizada.\n",
      "Columna position actualizada.\n",
      "Columna standing_reach_ft_in actualizada.\n",
      "Datos actualizados exitosamente en la tabla BorradorDeEstadsticasCombinadas donde los valores eran NULL.\n",
      "Tabla temporal temp_draft_combine_stats eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "draft_combine_stats = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\draft_combine_stats.csv')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_draft_combine_stats'\n",
    "draft_combine_stats.to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Actualizar las columnas en la tabla BorradorDeEstadsticasCombinadas usando la tabla temporal\n",
    "columns_to_update = [\n",
    "    'first_name', 'last_name', 'player_name', 'position', 'standing_reach_ft_in'\n",
    "]\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    for column in columns_to_update:\n",
    "        update_query = f\"\"\"\n",
    "        UPDATE BorradorDeEstadsticasCombinadas\n",
    "        SET BorradorDeEstadsticasCombinadas.{column} = temp_draft_combine_stats.{column}\n",
    "        FROM BorradorDeEstadsticasCombinadas\n",
    "        JOIN temp_draft_combine_stats ON BorradorDeEstadsticasCombinadas.player_name = temp_draft_combine_stats.player_name\n",
    "        WHERE BorradorDeEstadsticasCombinadas.{column} IS NULL;\n",
    "        \"\"\"\n",
    "        connection.execute(text(update_query))\n",
    "        print(f\"Columna {column} actualizada.\")\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla BorradorDeEstadsticasCombinadas donde los valores eran NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_draft_history\n",
      "Columna player_name actualizada.\n",
      "Columna draft_type actualizada.\n",
      "Columna team_city actualizada.\n",
      "Columna team_name actualizada.\n",
      "Columna team_abbreviation actualizada.\n",
      "Columna organization actualizada.\n",
      "Columna organization_type actualizada.\n",
      "Datos actualizados exitosamente en la tabla BorradorDeHistoria donde los valores eran NULL.\n",
      "Tabla temporal temp_draft_history eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "draft_history = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\draft_history.csv')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_draft_history'\n",
    "draft_history.to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Actualizar las columnas en la tabla BorradorDeHistoria usando la tabla temporal\n",
    "columns_to_update = [\n",
    "    'player_name', 'draft_type', 'team_city', 'team_name', 'team_abbreviation', 'organization', 'organization_type'\n",
    "]\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    for column in columns_to_update:\n",
    "        update_query = f\"\"\"\n",
    "        UPDATE BorradorDeHistoria\n",
    "        SET BorradorDeHistoria.{column} = temp_draft_history.{column}\n",
    "        FROM BorradorDeHistoria\n",
    "        JOIN temp_draft_history ON BorradorDeHistoria.person_id = temp_draft_history.person_id\n",
    "        WHERE BorradorDeHistoria.{column} IS NULL;\n",
    "        \"\"\"\n",
    "        connection.execute(text(update_query))\n",
    "        print(f\"Columna {column} actualizada.\")\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla BorradorDeHistoria donde los valores eran NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_team_history\n",
      "Columna city actualizada.\n",
      "Columna nickname actualizada.\n",
      "Datos actualizados exitosamente en la tabla HistoriaDelEquipo donde los valores eran NULL.\n",
      "Tabla temporal temp_team_history eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "team_history = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\team_history.csv')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_team_history'\n",
    "team_history.to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Actualizar las columnas en la tabla HistoriaDelEquipo usando la tabla temporal\n",
    "columns_to_update = ['city', 'nickname']\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    for column in columns_to_update:\n",
    "        update_query = f\"\"\"\n",
    "        UPDATE HistoriaDelEquipo\n",
    "        SET HistoriaDelEquipo.{column} = temp_team_history.{column}\n",
    "        FROM HistoriaDelEquipo\n",
    "        JOIN temp_team_history ON HistoriaDelEquipo.team_id = temp_team_history.team_id\n",
    "        WHERE HistoriaDelEquipo.{column} IS NULL;\n",
    "        \"\"\"\n",
    "        connection.execute(text(update_query))\n",
    "        print(f\"Columna {column} actualizada.\")\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla HistoriaDelEquipo donde los valores eran NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_game\n",
      "Columna team_abbreviation_home actualizada.\n",
      "Columna team_name_home actualizada.\n",
      "Columna matchup_home actualizada.\n",
      "Columna wl_home actualizada.\n",
      "Columna fg_pct_home actualizada.\n",
      "Columna team_abbreviation_away actualizada.\n",
      "Columna team_name_away actualizada.\n",
      "Columna matchup_away actualizada.\n",
      "Columna wl_away actualizada.\n",
      "Columna fgm_away actualizada.\n",
      "Columna fg_pct_away actualizada.\n",
      "Columna season_type actualizada.\n",
      "Datos actualizados exitosamente en la tabla Juego donde los valores eran NULL.\n",
      "Tabla temporal temp_game eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "game_data = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\game.csv')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_game'\n",
    "game_data.to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Actualizar las columnas en la tabla Juego usando la tabla temporal\n",
    "columns_to_update = [\n",
    "    'team_abbreviation_home', 'team_name_home', 'matchup_home', 'wl_home', 'fg_pct_home',\n",
    "    'team_abbreviation_away', 'team_name_away', 'matchup_away', 'wl_away', 'fgm_away', 'fg_pct_away', 'season_type'\n",
    "]\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    for column in columns_to_update:\n",
    "        update_query = f\"\"\"\n",
    "        UPDATE Juego\n",
    "        SET Juego.{column} = temp_game.{column}\n",
    "        FROM Juego\n",
    "        JOIN temp_game ON Juego.game_id = temp_game.game_id\n",
    "        WHERE Juego.{column} IS NULL;\n",
    "        \"\"\"\n",
    "        connection.execute(text(update_query))\n",
    "        print(f\"Columna {column} actualizada.\")\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla Juego donde los valores eran NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_game\n",
      "Columna team_abbreviation_home actualizada.\n",
      "Columna team_name_home actualizada.\n",
      "Columna matchup_home actualizada.\n",
      "Columna wl_home actualizada.\n",
      "Columna fg_pct_home actualizada.\n",
      "Columna team_abbreviation_away actualizada.\n",
      "Columna team_name_away actualizada.\n",
      "Columna matchup_away actualizada.\n",
      "Columna wl_away actualizada.\n",
      "Columna fgm_away actualizada.\n",
      "Columna fg_pct_away actualizada.\n",
      "Columna season_type actualizada.\n",
      "Datos actualizados exitosamente en la tabla Juego donde los valores eran NULL.\n",
      "Tabla temporal temp_game eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "game_data = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\game.csv')\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_game'\n",
    "game_data.to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Actualizar las columnas en la tabla Juego usando la tabla temporal\n",
    "columns_to_update = [\n",
    "    'team_abbreviation_home', 'team_name_home', 'matchup_home', 'wl_home', 'fg_pct_home',\n",
    "    'team_abbreviation_away', 'team_name_away', 'matchup_away', 'wl_away', 'fgm_away', 'fg_pct_away', 'season_type'\n",
    "]\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    for column in columns_to_update:\n",
    "        update_query = f\"\"\"\n",
    "        UPDATE Juego\n",
    "        SET Juego.{column} = temp_game.{column}\n",
    "        FROM Juego\n",
    "        JOIN temp_game ON Juego.season_id = temp_game.season_id\n",
    "        WHERE Juego.{column} IS NULL;\n",
    "        \"\"\"\n",
    "        connection.execute(text(update_query))\n",
    "        print(f\"Columna {column} actualizada.\")\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla Juego donde los valores eran NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_game\n",
      "Columna team_abbreviation_home actualizada.\n",
      "Columna team_name_home actualizada.\n",
      "Columna matchup_home actualizada.\n",
      "Columna season_type actualizada.\n",
      "Datos actualizados exitosamente en la tabla Juego donde los valores eran NULL.\n",
      "Tabla temporal temp_game eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "game_data = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\game.csv')\n",
    "\n",
    "# Reemplazar todas las variantes de NaN con None para manejar valores NULL en SQL Server\n",
    "game_data = game_data.replace(['NaN', 'nan'], None)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_game'\n",
    "game_data.to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Actualizar las columnas en la tabla Juego usando la tabla temporal\n",
    "columns_to_update = [\n",
    "    'team_abbreviation_home', 'team_name_home', 'matchup_home', 'season_type'\n",
    "]\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    for column in columns_to_update:\n",
    "        update_query = f\"\"\"\n",
    "        UPDATE Juego\n",
    "        SET Juego.{column} = temp_game.{column}\n",
    "        FROM Juego\n",
    "        JOIN temp_game ON Juego.season_id = temp_game.season_id\n",
    "        WHERE Juego.{column} IS NULL;\n",
    "        \"\"\"\n",
    "        connection.execute(text(update_query))\n",
    "        print(f\"Columna {column} actualizada.\")\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla Juego donde los valores eran NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_game\n",
      "Columna team_abbreviation_home actualizada.\n",
      "Columna team_name_home actualizada.\n",
      "Columna matchup_home actualizada.\n",
      "Columna season_type actualizada.\n",
      "Datos actualizados exitosamente en la tabla Juego donde los valores eran NULL.\n",
      "Tabla temporal temp_game eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "game_data = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\game.csv')\n",
    "\n",
    "# Reemplazar todas las variantes de NaN y nan con None para manejar valores NULL en SQL Server\n",
    "game_data = game_data.replace(['NaN', 'nan'], None)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_game'\n",
    "game_data.to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Actualizar las columnas en la tabla Juego usando la tabla temporal\n",
    "columns_to_update = [\n",
    "    'team_abbreviation_home', 'team_name_home', 'matchup_home', 'season_type'\n",
    "]\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    for column in columns_to_update:\n",
    "        update_query = f\"\"\"\n",
    "        UPDATE Juego\n",
    "        SET Juego.{column} = temp_game.{column}\n",
    "        FROM Juego\n",
    "        JOIN temp_game ON Juego.season_id = temp_game.season_id\n",
    "        WHERE Juego.{column} IS NULL;\n",
    "        \"\"\"\n",
    "        connection.execute(text(update_query))\n",
    "        print(f\"Columna {column} actualizada.\")\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla Juego donde los valores eran NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bianc\\AppData\\Local\\Temp\\ipykernel_15124\\3364620585.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  existing_data[column].fillna(game_data[column], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos actualizados exitosamente en la tabla Juego.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Leer el archivo CSV\n",
    "game_data = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\game.csv')\n",
    "\n",
    "# Reemplazar todas las variantes de NaN y nan con None para manejar valores NULL en SQL Server\n",
    "game_data.replace(['NaN', 'nan'], None, inplace=True)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Leer los datos existentes en la tabla Juego\n",
    "existing_data = pd.read_sql('SELECT * FROM Juego', con=engine)\n",
    "\n",
    "# Actualizar las columnas con valores de game_data donde haya valores NaN\n",
    "columns_to_update = [\n",
    "    'team_abbreviation_home', 'team_name_home', 'matchup_home', 'wl_home', 'fg_pct_home',\n",
    "    'team_abbreviation_away', 'team_name_away', 'matchup_away', 'wl_away', 'fgm_away', 'fg_pct_away', 'season_type'\n",
    "]\n",
    "\n",
    "for column in columns_to_update:\n",
    "    existing_data[column].fillna(game_data[column], inplace=True)\n",
    "\n",
    "# Subir los datos actualizados nuevamente a la tabla Juego\n",
    "existing_data.to_sql('Juego', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla Juego.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados en la tabla temporal temp_line_score\n",
      "Columna game_sequence actualizada.\n",
      "Columna pts_qtr1_home actualizada.\n",
      "Columna pts_qtr2_home actualizada.\n",
      "Columna pts_qtr3_home actualizada.\n",
      "Columna pts_qtr4_home actualizada.\n",
      "Columna pts_ot1_home actualizada.\n",
      "Columna pts_ot2_home actualizada.\n",
      "Columna pts_ot3_home actualizada.\n",
      "Columna pts_ot4_home actualizada.\n",
      "Columna pts_ot5_home actualizada.\n",
      "Columna pts_ot6_home actualizada.\n",
      "Columna pts_ot7_home actualizada.\n",
      "Columna pts_ot8_home actualizada.\n",
      "Columna pts_ot9_home actualizada.\n",
      "Columna pts_ot10_home actualizada.\n",
      "Columna pts_qtr1_away actualizada.\n",
      "Columna pts_qtr2_away actualizada.\n",
      "Columna pts_qtr3_away actualizada.\n",
      "Columna pts_qtr4_away actualizada.\n",
      "Columna pts_ot1_away actualizada.\n",
      "Columna pts_ot2_away actualizada.\n",
      "Columna pts_ot3_away actualizada.\n",
      "Columna pts_ot4_away actualizada.\n",
      "Columna pts_ot5_away actualizada.\n",
      "Columna pts_ot6_away actualizada.\n",
      "Columna pts_ot7_away actualizada.\n",
      "Columna pts_ot8_away actualizada.\n",
      "Columna pts_ot9_away actualizada.\n",
      "Columna pts_ot10_away actualizada.\n",
      "Datos actualizados exitosamente en la tabla PuntuacionDeLinea donde los valores eran NULL.\n",
      "Tabla temporal temp_line_score eliminada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "line_score_data = pd.read_csv(r'C:\\Users\\bianc\\OneDrive\\Escritorio\\NBA DASHBOARD\\line_score.csv')\n",
    "\n",
    "# Reemplazar todas las variantes de NaN y nan con None para manejar valores NULL en SQL Server\n",
    "line_score_data.replace(['NaN', 'nan'], None, inplace=True)\n",
    "\n",
    "# Crear la conexión con SQL Server usando autenticación de Windows\n",
    "engine = create_engine('mssql+pyodbc://BIANCA\\\\SQLEXPRESS/NBA?trusted_connection=yes&driver=ODBC Driver 18 for SQL Server&TrustServerCertificate=yes')\n",
    "\n",
    "# Crear una tabla temporal en la base de datos SQL Server\n",
    "temp_table_name = 'temp_line_score'\n",
    "line_score_data.to_sql(temp_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Datos cargados en la tabla temporal {temp_table_name}\")\n",
    "\n",
    "# Actualizar las columnas en la tabla PuntuacionDeLinea usando la tabla temporal\n",
    "columns_to_update = [\n",
    "    'game_sequence', 'pts_qtr1_home', 'pts_qtr2_home', 'pts_qtr3_home', 'pts_qtr4_home', 'pts_ot1_home',\n",
    "    'pts_ot2_home', 'pts_ot3_home', 'pts_ot4_home', 'pts_ot5_home', 'pts_ot6_home', 'pts_ot7_home',\n",
    "    'pts_ot8_home', 'pts_ot9_home', 'pts_ot10_home', 'pts_qtr1_away', 'pts_qtr2_away', 'pts_qtr3_away',\n",
    "    'pts_qtr4_away', 'pts_ot1_away', 'pts_ot2_away', 'pts_ot3_away', 'pts_ot4_away', 'pts_ot5_away',\n",
    "    'pts_ot6_away', 'pts_ot7_away', 'pts_ot8_away', 'pts_ot9_away', 'pts_ot10_away'\n",
    "]\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    for column in columns_to_update:\n",
    "        update_query = f\"\"\"\n",
    "        UPDATE PuntuacionDeLinea\n",
    "        SET PuntuacionDeLinea.{column} = temp_line_score.{column}\n",
    "        FROM PuntuacionDeLinea\n",
    "        JOIN temp_line_score ON PuntuacionDeLinea.game_id = temp_line_score.game_id\n",
    "        WHERE PuntuacionDeLinea.{column} IS NULL;\n",
    "        \"\"\"\n",
    "        connection.execute(text(update_query))\n",
    "        print(f\"Columna {column} actualizada.\")\n",
    "\n",
    "print(\"Datos actualizados exitosamente en la tabla PuntuacionDeLinea donde los valores eran NULL.\")\n",
    "\n",
    "# Eliminar la tabla temporal después de la actualización\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"DROP TABLE {temp_table_name}\"))\n",
    "\n",
    "print(f\"Tabla temporal {temp_table_name} eliminada.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
